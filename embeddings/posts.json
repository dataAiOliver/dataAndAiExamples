{
    "apple": [
        "<p>What is the hardware and software differences between Intel and PPC Macs?</p>\n",
        "<p>The VPN software I use for work (<a href=\"http://www.lobotomo.com/products/IPSecuritas/\">IPSecuritas</a>) requires me to turn off Back To My Mac to start it's connection, so I frequently turn off Back To My Mac in order to use my VPN connection (the program does this for me). I forget to turn it back on however and I'd love to know if there was something I could run (script, command) to turn it back on.</p>\n",
        "<p>I have Microsoft Office/2008 on my MacBook Pro. Office doesn't support RTL languages like Farsi and Arabic, and I know that Office/2010 (for Windows) also has the same problem.</p>\n\n<p>Do you think the lack of support is because of business competition, or some other reason?</p>\n",
        "<p>I had a power failure and upon rebooting noticed that the OS drive needed to be repaired (Disk Utilities). I am running Snow Leopard and don't have the CD to start up from in order to perform the fix.</p>\n\n<p>Are there any other options for running the repair utils on the startup disk?</p>\n",
        "<p>I will often click on a button expecting it to be clicked but instead all that happens is the application it is in becomes active, and I have to click again to actually click the button.  It would be nice if this second click wasn't needed, which leads me to my question:</p>\n\n<blockquote>\n  <p>How can I make it so that when I move the mouse cursor over an inactive window, it becomes active?</p>\n</blockquote>\n",
        "<p>One option would be to clone your startup drive to an external disk using something like SuperDuper! or Carbon Copy Cloner. Then you can use System Preferences->Startup Disk to select that external drive as the boot drive. </p>\n\n<p>Once you've rebooted and are running the system off the external drive you can use Disk Utility to run the repair. After you're done, re-select the internal drive as the Startup Disk and reboot.</p>\n",
        "<p>I originally wanted to do this with my first Mac a couple years ago as well, since that's how my Linux and Windows environments behave.  But I think the driving force preventing this from becoming a reality is in how OS X handles application menus.</p>\n\n<p>What if you want to go to the menu at the top of the screen for an application you're using, but in the process briefly hover over another application?  That would become infuriating quickly.</p>\n\n<p>In short, I don't think its doable for that and potentially other reasons.</p>\n",
        "<p>Microsoft has dragged their heels on support for RTL languages such as Hebrew and Arabic for years. It's always been 'coming in the next version' for as long as I've been using a Mac. Until it shows up, if it ever does, the premiere word processor for RTL languages on OS X is <a href=\"http://www.redlers.com/mellel.html\" rel=\"nofollow\">Mellel.</a> It's actually quite great.</p>\n",
        "<p>Hardware-wise: PowerPC is a microprocessor developed mainly by the three developing companies Apple, IBM, and Motorola. It is built with reduced instruction-set computer (RISC) which speeds-up the operation of MIPS (million instructions per second). PowerPC is mainly based on IBM\u2019s earlier Power architecture because it has a similar RISC instruction set for microprocessors.</p>\n\n<p>Intel and AMD CPU's are based on CISC architectures. Typically CISC chips have a large amount of different and complex instructions. The philosophy behind it is that hardware is always faster than software, therefore one should make a powerful instructionset, which provides programmers with assembly instructions to do a lot with short programs.\nIn common CISC chips are relatively slow (compared to RISC chips) per instruction, but use little (less than RISC) instruction</p>\n",
        "<p>In Spaces it's possible to specify which space a given application will open on -- for example, my web browser always opens on Space 1 and iTunes on Space 3.  Is something similar possible with multiple monitors, so that whichever space I'm on a certain application will always open on the second monitor?  For even more control, can I specify that it will always open on Monitor 2 of Space 4?</p>\n",
        "<p>Everytime I turn on my Macbook Pro it makes a start up noise. This is annoying since there is no volume or ability to turn it off. I just don't want the sound to play at all.</p>\n\n<p>How do I disable this startup sound?</p>\n",
        "<p>Does the iPhone close the background programs if it runs out of memory or battery?</p>\n",
        "<p>\u201cWhy\u201d is a question for Microsoft, but I'm guessing it boils down to a simple lack of resources on the part of the Mac Business Unit. They have to prioritize certain features, and RTL support is not a priority for them.</p>\n\n<p>To address the underlying need, you have several options:</p>\n\n<p>OpenOffice and NeoOffice support RTL text in Microsoft Office documents.</p>\n\n<p>Mellel has a reputation as the best RTL/multilingual word processor (it certainly has a nice feature set for it, like a <a href=\"http://www.redlers.com/mellelmultilingual.html\" rel=\"nofollow\">direction breaking space</a> so you can mix RTL/LTR in a paragraph), but I don\u2019t know how good its Microsoft Office document interoperability is.</p>\n\n<p>This would also be a use case where it might make sense to run Office 2010 inside a Windows virtual machine.</p>\n",
        "<p>PPC Macs refers to the generation of Macintosh computers created in the mid to late 1990s through to 2006 that used PowerPC RISC based chips made by IBM or Motorola. That last PowerPC based Macintosh, the PowerMac G5 stopped being sold in August 2006. The latest version of Mac OS X a PowerPC chip enabled computer was able to run was Mac OS X 10.5 (Leopard) (so long as the computer supported it).</p>\n\n<p>Intel Macs refers to the newer Macintosh computers (since January 2006) that use Intel's CISC processors. Intel Macs uses EFI instead of BIOS and can run the latest versions of Mac OS X. Intel Macs are also able to run PowerPC compiled applications through a translation layer called Rosetta which is optionally installed in 10.6.</p>\n\n<p>If a program is made available as a Universal binary it is able to run on both PPC and Intel Macs however many new applications released today are Intel only (eg. Google Chrome, Final Cut Studio, Mac OS X Snow Leopard).</p>\n",
        "<p>I am looking for a \"word-of-the-day\" screensaver or dashboard widget where I can configure (e.g. in a text file) that \"words\" to be displayed?</p>\n",
        "<p>You can use <a href=\"http://www5e.biglobe.ne.jp/~arcana/index.en.html\">StartSound.PrefPane</a> which basically just sets the volume to 0 when you shutdown and then turns it back up after login.</p>\n",
        "<p>One thing I know is that PPCs are big endian by default, but <a href=\"http://en.wikipedia.org/wiki/PowerPC#Endian_modes\" rel=\"nofollow\">can switch modes</a> if necessary. Intel are little endian.</p>\n",
        "<p>I have a 2007 Macbook Pro and for nearly two years, the battery has been toast. In April, Apple replaced the logic board. Since the repair, whenever the power cable comes loose, the MBP shuts off as expected. </p>\n\n<p>Before the repair, when the power cable was unplugged, the MBP simply shut off. Now, when I plug it back in and turn it on, it boots back up in the previous state, but has a white screen with loading bars at the bottom.</p>\n\n<p>I haven't found anything related to this on the web. Is this related to the new logic board, or is there something else I should be concerned about? The MBP is running Leopard and is up to date.</p>\n",
        "<p>From the end user point of view, you don't need to worry about it much. Many applications were produced as \"universal\", meaning they run on both PPC and Intel-based Macs, and an emulator (called Rosetta) would let PPC-only apps run on the new Intel machines. </p>\n\n<p>However, as time passed, newer features were only available to Intel Macs, so some applications state outright that they require Intel chips. Also, the latest version of Mac OS X only runs on Intel CPUs.</p>\n\n<p>Apple did a reasonably good job of hiding the entire transition from users, so that everything just kept working as people expected, offloading any heavy lifting to software developers.</p>\n",
        "<p>I've used ShakesPeer for it's clean and Mac-like interface. But the downloads are really slow. Is there a faster alternative to ShakesPeer?</p>\n\n<p>Preferably having at least the same features as ShakesPeer itself if not more. Also preferable if the software follows the Apple Human Interface Guidelines.</p>\n",
        "<p>No. Even restarting, complete power down and power up, will not remove the background applications from memory. According to the Apple Geniuses you must manually remove the applications from the task bar.</p>\n",
        "<p>This is so called \"Hibernation\" (my first met in windows). When battery dies, the OS dumps whole RAM into HDD (sort of swapping) so that no information is lost. When it's being booted back up, it loads the information back from HDD to RAM (hence you see the progress with those white bars).</p>\n",
        "<p>When it comes to Apple hardware, the differences between the last generation of PowerPC and the first generation of Intel were fairly minor, as far as the end user experience goes. They used the same form factors, and the all-new internals were quite effectively hidden by the unchanged exterior and the accommodations the operating system made for compatibility.</p>\n\n<p>The last PowerPC Macs were sold in 2006, so any new machine since then is Intel.</p>\n\n<p>In general, Intel Macs can run the vast majority of software created for PowerPC Macs. There is a performance hit for the emulation required, but it runs at acceptable speeds even for complex software like Photoshop. PowerPC Macs cannot run Intel software.</p>\n\n<p>The latest version of OS X, Snow Leopard, is available only for Intel-based Macs.</p>\n\n<p>Intel Macs have access to a feature called Boot Camp, which allows them to boot into Windows at full speed. Intel Macs can also run Windows inside virtual machines with the help of third-party software (<a href=\"http://www.vmware.com/products/fusion/\">VMWare Fusion</a>, <a href=\"http://www.virtualbox.org/\">VirtualBox</a> or <a href=\"http://www.parallels.com/products/desktop/\">Parallels</a>); there is a minor performance penalty for this, but it's much faster than the emulation required for a PowerPC Mac to run Windows software.</p>\n",
        "<p>This feature is called Safe Sleep. Apple notebooks will keep the RAM contents alive (sleep in PC jargon), but write a copy to the disk (hibernate, in PC jargon) at the same time.</p>\n\n<p>If the battery runs out while the computer is sleeping, when it wakes up, it needs to read the RAM contents from disk, and thus you get the progress bar you are seeing.</p>\n\n<p>Apple doc about it is <a href=\"http://support.apple.com/kb/HT1757?viewlocale=en_US\">here</a></p>\n",
        "<p>Architecture:</p>\n\n<p>PowerPC: (short for Performance Optimization With Enhanced RISC \u2013 Performance Computing, sometimes abbreviated as PPC) and Intel processor.</p>\n\n<p>more information can be found at wikipedia: <a href=\"http://en.wikipedia.org/wiki/PowerPC\" rel=\"nofollow\">PowerPC</a></p>\n",
        "<p>They aren't really \"in memory,\" more like cached to disk if and when necessary. Many apps don't even use the multitasking or aren't setup for it. When you switch it does actually close the app.</p>\n\n<p>Being in the task bar doesn't guarantee that it's actually in memory, actively running, or both. The OS manages that. </p>\n",
        "<p>On my Jailbroken iPad, I have SBSettings installed. I chose to hide all my application icons, but iPod will not go away, no matter what the switch setting is. I was thinking about just going into the file system and manually deleting the icon, but I don't know where it's stored.   </p>\n\n<p>Any suggestions?</p>\n\n<p><a href=\"https://i.stack.imgur.com/uwohA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/uwohA.png\" alt=\"\"></a></p>\n",
        "<p>I'm about to travel to the US, where iPods / AirPods / iPhone are much cheaper than in my country. </p>\n\n<p>I wonder if Apple's warranty is international, and/or what warranty coverage exists when I return to my country.</p>\n\n<p>Where can I understand what Apple Warranty covers in the US when products leave the US?</p>\n",
        "<p>Not with the default Apple Spaces.</p>\n\n<p>There is an alternative, though. CocoaBots makes a small app called Hyperspaces which builds upon the default Spaces and adds a bunch of cool features. Multi-monitor support is coming to their next release.</p>\n\n<p><a href=\"http://thecocoabots.com/blog/post/148/hyperspaces-104-and-the-road-to-11/\" rel=\"nofollow\">http://thecocoabots.com/blog/post/148/hyperspaces-104-and-the-road-to-11/</a></p>\n",
        "<p>There are two ways to approach this question.</p>\n\n<p>From the end user's perspective, the answer is no. No matter what you do, the app will come back to the same state it was in previously, unless you close it from the switching interface.</p>\n\n<p>Technically: yes. When the device runs short on RAM, it will freeze the application's state from RAM to the main storage (flash). When you resume, it loads the state from flash back into RAM, and then resumes. This is intended to happen quickly enough and transparently enough to be indistinguishable, but you may sometimes notice that resuming takes a bit longer if you have loaded several other apps in the meantime (and therefore pushed the app out of RAM). </p>\n",
        "<p>If I have an iPod Touch backup on my computer, can an iPhone restore from it? How about vice versa?</p>\n",
        "<p>I received a hand me down white MacBook with 10.4 on it and it automatically logs into a user account that isn't able to change much in the preference pane. How do I recover or change the administrator password?</p>\n\n<p>The original owner told me to try a few passwords, none of which work to get logged in as admin.</p>\n",
        "<p>Is there a way to close all application in the taskbar at once?</p>\n",
        "<p>I haven't tried these but Jucy and EiskaltDC++ are two DirectConnect clients that work on mac.  However, neither appears to use a mac interface.</p>\n\n<p>source: <a href=\"http://alternativeto.net/desktop/shakespeer/?sort=likes&amp;platform=mac\" rel=\"nofollow\">http://alternativeto.net/desktop/shakespeer/?sort=likes&amp;platform=mac</a></p>\n",
        "<p><a href=\"http://forums.macrumors.com/showthread.php?t=527801\" rel=\"nofollow\">According to this forums post</a>, somebody did it with success.</p>\n\n<blockquote>\n  <p><strong>Worked flawlessly for me</strong><br>\n  I just activated my new iPhone 3GS and then iTunes offered to either set it up as a new iPhone or to restore it from my iPod Touch backup which I did. No problems so far...</p>\n</blockquote>\n",
        "<p>Boot to OS recovery, internet recovery or on older systems, with a Mac OS X DVD, then there's an option to change passwords.</p>\n\n<p><img src=\"https://i.stack.imgur.com/o5Glq.jpg\" alt=\"reset\"></p>\n\n<p>You can follow an how-to <a href=\"http://osxdaily.com/2010/02/21/reset-a-lost-password-in-mac-os-x/\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
        "<p>AFAIK - there's word-of-the-day screensaver that comes packed with every Mac OS X (since Tiger). You can configure it on a \"per dictionary\" basis. So if you need a limited list of some words, just create your own dictionary, install it on the system and I believe you'll be able to use it in a screensaver yourself.</p>\n",
        "<p>When installing Tiger or Leopard, there was an option called \"Erase and Install\" that would delete the disk before installing the new OS.</p>\n\n<p>In Snow Leopard, this option seems to be missing. Is there any way I can add \"Erase and Install\" back to Snow Leopard?</p>\n",
        "<p>You can reboot into <a href=\"http://support.apple.com/kb/ht1492\">single user mode</a> and change the password of a user with:</p>\n\n<pre><code>passwd [user]\n</code></pre>\n\n<p>Enter the new password twice and reboot.</p>\n",
        "<p>Yes, Apple's computer warranties are international. Worst case, you have to ship your product back to the purchasing country if Apple asks for that, but the wording and common practice is U.S. purchases generally get covered everywhere Apple has service globally.</p>\n<p>See <a href=\"http://www.apple.com/legal/warranty/\" rel=\"noreferrer\">Apple's Warranty Page</a> for more details. The warranty is established in the country of purchase and if warranty service is not available in the country where the device is when service is requested, you may be on the hook for import/export duties as well as paying for the shipping.</p>\n<p>No, iPhone and some parts of AppleCare plus are not necessarily international.</p>\n<ul>\n<li><a href=\"https://www.apple.com/legal/warranty/\" rel=\"noreferrer\">https://www.apple.com/legal/warranty/</a></li>\n</ul>\n<p>Pay attention to parts like:</p>\n<blockquote>\n<p>IMPORTANT RESTRICTION FOR iPHONE, iPAD AND APPLE TV SERVICE.</p>\n<p>Apple may restrict warranty service for iPhone, iPad and Apple TV to the country where Apple or its Authorized Distributors originally sold the device.</p>\n</blockquote>\n<p>That doesn\u2019t mean you won\u2019t get service, but you could be denied or could have to get the device back to the country of purchase on your dime to get service.</p>\n<p>Also, no in terms of consumer law varying widely between Europe, Asia, US and other countries:</p>\n<ul>\n<li><a href=\"https://apple.stackexchange.com/questions/48730/how-does-apples-two-year-warranty-in-europe-work\">How does Apple&#39;s two year warranty in Europe work?</a></li>\n</ul>\n<p>To recap:</p>\n<ul>\n<li>Warranty is what Apple offers and you may have responsibilities or costs to get service</li>\n<li>Consumer law covers things outside the warranty, so you need to balance both when choosing where to buy</li>\n<li>Look for words like shall and may and must - these contracts are legal and  /or prescriptive so details and words matter. Read all the document, several times before spending money if you don\u2019t know the return policy or have limited time to return goods after purchasing them.</li>\n</ul>\n",
        "<p>Use the tools menu --> disk utility to erase the partition you want to install Snow Leopard on.  Then proceed with the installation.</p>\n",
        "<p>I'm using my wife's Macbook with the bigger multitouch track pad. Many times while in Safari, it thinks I want to zoom in and the page will zoom in. I want to just get rid of multitouch in Safari, or just disable the zoom feature in Safari.</p>\n\n<p>It's nice to have multitouch in other applications like iPhoto, but it just causes problems in Safari.</p>\n",
        "<h3>No.</h3>\n\n<p>You have to manually remove each one.</p>\n",
        "<p>Apple Warranty is international and you can use your warranty on every country that apple has branch.</p>\n\n<p>but other than warranty you can buy AppleCare Protection.\nApple has \u201cglobal repair coverage\u201d If you carry your Apple computer or iPod when you travel and happen to need repair service, AppleCare Protection Plan offers global repair coverage.</p>\n\n<p>but for this you need to purchase AppleCare Protection , and if you want go to other country to buy your product cheaper AppleCare Protection not a good Idea. </p>\n",
        "<p>I am being asked to setup my keyboard every time I reboot my computer. Is there anyway I can get this to keep the setup?</p>\n\n<p>I am on Snow Leopard and have a Logitech Wave wireless keyboard and mouse combo. This started happening when I switched to 64-bit mode. Booting into 32-bit mode doesn't fix it.</p>\n",
        "<p>I'm getting a new laptop and I want to move my iTunes library from the old to the new computer. How can I do this? Of course I want to preserve as much information as possible: metadata such as ratings and play counts, cover art, my purchased content from Apple.</p>\n\n<p>I also own an iPhone which I used to sync with the old computer and now I want to sync with the new one, preserving my apps, contacts, purchased content, etc.</p>\n\n<p>What would be the best way to do this? Is just moving the whole \u201ciTunes\u201d folder from one computer to the other an option?</p>\n",
        "<p>With Snow Leopard Erase and Install is now a two step process:</p>\n\n<ol>\n<li>When you start up off the Mac OS X Install DVD from the Tools menu choose \"Disk Utility\". You will then want to erase the hard drive you want to install on.</li>\n<li>Install Mac OS X as you would normally. </li>\n</ol>\n",
        "<p>Because Snow Leopard is an technically a Leopard upgrade it might not be readily accessible.</p>\n\n<p>You can boot up and under the \"Tools\" menu open up Disk Utility to erase before you install.</p>\n",
        "<p>Yes it's international.</p>\n\n<p>My friend bought a MacBook in the US and had a warranty case in Switzerland. The warranty case got solved without any problems.</p>\n",
        "<p>If they both have Firewire you can simply use the <a href=\"http://www.apple.com/pro/tips/migration.html\" rel=\"nofollow\">Migration Utility</a>.</p>\n",
        "<p>My MacBook Pro takes an awful long time to go to sleep when I close the lid. Considering that I generally want to close the lid and then carry it somewhere, I want it to be fully asleep so I don't have any hard drive issues. Is there anything I can do to speed up the process?</p>\n"
    ],
    "astronomy": [
        "<p>Suppose I would like to calculate the inclination of a satellite from the <strong>ecliptic</strong>. Would it be possible to do this with an amateur telescope? How would I go about doing so?</p>\n\n<hr>\n\n<p>Note: A good answer should tell what kind of telescope an amateur would need, what measurements they would need to make, then what calculations they would have to perform to get the inclination (or the \"instantaneous angular measurement from the ecliptic at the time of measurement\").</p>\n",
        "<p>How are exoplanetary atmosphere compositional spectra distinguished from those of the parent star(s), from the composition of the planetary surface or any other factor?  Is it actually possible to determine the atmospheric composition precisely using this method?</p>\n\n<p>Are there any specific examples of such an analysis having been performed on an exoplanet?</p>\n",
        "<p>Are there any easily resolvable, binary star, observing targets visible from ~N40\u00b0?</p>\n\n<p>I'd like to be able to show, in one observing session, Mizar and Alcor (naked eye resolvable), another with binoculars, and finally one in a small (say, 4 to 6\" reflector) amateur scope.</p>\n",
        "<p>Sunspots, such as this one, appear dark:</p>\n\n<p><img src=\"https://i.stack.imgur.com/VM9qym.jpg\" alt=\"sunspot\"></p>\n\n<p>Why?</p>\n",
        "<p>Typical sunspots have a dark region (umbra) surrounded by a lighter region, the penumbra. While sunspots have a temperature of about 6300 \u00b0F (3482.2 \u00b0C), the surface of the sun which surrounds it has a temperature of 10,000 \u00b0F (5537.8 \u00b0C).</p>\n<p>From <a href=\"https://image.gsfc.nasa.gov/poetry/workbook/sunspot.html\" rel=\"nofollow noreferrer\">this NASA resource</a>:</p>\n<blockquote>\n<p>Sunspots are actually regions of the solar surface where the magnetic field of the Sun becomes concentrated over 1000-fold. Scientists do not yet know how this happens. Magnetic fields produce pressure, and this pressure can cause gas inside the sunspot to be in balance with the gas outside the sunspot...but at a lower temperature. Sunspots are actually several thousand degrees cooler than the 5,770 K (5496.8 \u00b0C) surface of the Sun, and contain gases at temperature of 3000 to 4000 K (2726.9 - 3726.8 \u00b0C). They are dark only by contrast with the much hotter solar surface. <strong>If you were to put a sunspot in the night sky, it would glow brighter than the Full Moon with a crimson-orange color!</strong></p>\n</blockquote>\n<p>Sunspots are areas of intense magnetic activity, as is apparent in this image:</p>\n<p><img src=\"https://image.gsfc.nasa.gov/poetry/workbook/sunspot1.jpg\" alt=\"sunspot\" /></p>\n<p>You can see the material kind of getting stretched into strands.</p>\n<p>As for the <em>reason</em> it is cooler than the rest of the surface:</p>\n<blockquote>\n<p>Although the details of sunspot generation are still a matter of research, it appears that sunspots are the visible counterparts of <a href=\"http://en.wikipedia.org/wiki/Magnetic_flux_tube\" rel=\"nofollow noreferrer\">magnetic flux tubes</a> in the Sun's <a href=\"http://en.wikipedia.org/wiki/Convection_zone\" rel=\"nofollow noreferrer\">convective zone</a> that get &quot;wound up&quot; by <a href=\"http://en.wikipedia.org/wiki/Differential_rotation\" rel=\"nofollow noreferrer\">differential rotation</a>. If the stress on the tubes reaches a certain limit, they curl up like a rubber band and puncture the Sun's surface. <strong>Convection is inhibited at the puncture points; the energy flux from the Sun's interior decreases; and with it surface temperature.</strong></p>\n</blockquote>\n<p>All in all, the sunspots appear dark because the are darker <em>than the surrounding surface</em>. They're darker because they are cooler, and they're cooler because of the intense magnetic fields in them.</p>\n",
        "<p>I've heard that light can't escape from a <a href=\"http://en.wikipedia.org/wiki/Black_hole\">black hole</a>. Can it? If not, why?</p>\n",
        "<p>A black hole has an <a href=\"http://en.wikipedia.org/wiki/Event_horizon\" rel=\"nofollow noreferrer\">event horizon</a> which 'marks the point of no return'. So yes, light cannot escape from a black hole.</p>\n\n<p>Why? Well, think of a 'spacetime fabric'. It's the easiest way to understand the physics at work here, in my opinion.</p>\n\n<p>Usually, the fabric would look like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/7HKzL.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/7HKzL.jpg\" alt=\"fabric\"></a><br>\n<sub>(source: <a href=\"http://whyfiles.org/wp-content/uploads/2011/05/gravity_probespacetime.jpg\" rel=\"nofollow noreferrer\">whyfiles.org</a>)</sub>  </p>\n\n<p>However, a black hole has so much gravity that one could say it 'rips' the spacetime fabric:</p>\n\n<p><a href=\"https://i.stack.imgur.com/z4Pni.gif\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/z4Pni.gif\" alt=\"black hole fabric\"></a><br>\n<sub>(source: <a href=\"https://static.ddmcdn.com/gif/black-hole.gif\" rel=\"nofollow noreferrer\">ddmcdn.com</a>)</sub>  </p>\n\n<p>When the light hits this area of amazingly intense gravity, it simply cannot get out - the light travels 'along' the fabric, and since there is a rip in the fabric, one could say it simply goes away - it becomes part of the singularity.</p>\n\n<p>This is a simplification, of course, but it's enough to understand at least part of the physics behind this phenonenom.</p>\n",
        "<p>The equatorial coordinate system isn't too complicated. However, for people new to this, it seems rather intimidating at first.</p>\n\n<p>Is there an easy way to explain it?</p>\n",
        "",
        "Questions regarding planets that lie outside the Solar System.",
        "<p>In many movies and in the popular culture wormholes are often referenced, as well as \"faster than light travel\", which seems almost to be the same thing, is possible. \nAre astronomers seriously considering and researching this phenomenon? What could be the signature of wormholes? Would next generations telescopes as ELT able to detect such signatures?</p>\n",
        "<p>On Venus, there is really inhospitable weather, as well as within the gas giants in our solar system. Are there examples of even more extreme weather on planets found in other solar systems than ours?</p>\n",
        "<p>Why do we only ever see the same side of the moon?</p>\n\n<p>If this is to do with gravity are there any variables which mean we might one day see more than we have before?</p>\n",
        "",
        "Questions regarding Earth's moon and only natural satellite.",
        "<p>Questions regarding points of extremely high mass density, which creates an extremely strong gravitational field from which light cannot escape. Black holes are formed when a massive star (<span class=\"math-container\">$&gt;10M_\\odot$</span>) goes supernova and collapses into one.</p>\n",
        "Questions regarding points of extremely high mass density, which creates an extremely strong gravitational field from which light cannot escape.",
        "<p>This has been considered long ago (Here's <a href=\"http://physics.aps.org/story/v2/st7\">a paper</a> talking about this). </p>\n\n<p>Wormholes are not forbidden by physics, but the creation of wormholes is iffy ground. THere are two possible paths one can take to create a wormhole:</p>\n\n<ul>\n<li>Choose a pre-existing wormhole in the quantum foam and \"expand\" it by feeding it exotic matter.</li>\n<li>\"Tear and sew up\" space &mdash; we're not sure if this is allowed by physics, as it ventures into the area of physics that we don't have an adequate explanation for.</li>\n</ul>\n\n<p>Whatever it is, the creation and sustenance of a wormhole requires us to have control over <a href=\"http://en.wikipedia.org/wiki/Exotic_matter\">exotic matter</a> (in this case, particles/waves with negative mass/energy density). <a href=\"http://en.wikipedia.org/wiki/Quantum_fluctuation\">Vacuum fluctuations</a> already have regions of negative energy density, but they're an uncontrollable quantum phenomenon by current technology.</p>\n\n<p>\"Faster than light travel\" is a different matter, though. While wormholes let one jump to another point in space, one does not attain a speed greater than c whilst in them.</p>\n",
        "<p>The reason for this is what we call <strong><a href=\"https://en.wikipedia.org/wiki/Tidal_locking\" rel=\"noreferrer\">tidal locking</a></strong>:</p>\n<blockquote>\n<p>Tidal locking (or captured rotation) occurs when the <a href=\"https://en.wikipedia.org/wiki/Gravitational_gradient\" rel=\"noreferrer\">gravitational\ngradient</a> makes one side of an <a href=\"https://en.wikipedia.org/wiki/Astronomical_body\" rel=\"noreferrer\">astronomical body</a> always face another,\nan effect known as synchronous rotation. For example, the same side of\nthe Earth's Moon always faces the Earth. A tidally locked body takes\njust as long to rotate around its own axis as it does to revolve\naround its partner. This causes one hemisphere constantly to face the\npartner body. Usually, at any given time only the satellite is tidally\nlocked around the larger body, but if the difference in mass between\nthe two bodies and their physical separation is small, each may be\ntidally locked to the other, as is the case between <a href=\"https://en.wikipedia.org/wiki/Pluto\" rel=\"noreferrer\">Pluto</a> and <a href=\"https://en.wikipedia.org/wiki/Charon_(moon)\" rel=\"noreferrer\">Charon</a>.\nThis effect is employed to stabilize some artificial satellites.</p>\n</blockquote>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<img src=\"https://i.stack.imgur.com/kUqtd.gif\" alt=\"Tidal locking of the Moon with the Earth\" /></p>\n<p>\u00a0\u00a0\u00a0\u00a0<sup><strong>Fig. 1</strong>: Tidal locking results in the Moon rotating about its axis in about the same time it takes to orbit the Earth. (Source: <a href=\"https://en.wikipedia.org/wiki/File:Tidal_locking_of_the_Moon_with_the_Earth.gif\" rel=\"noreferrer\">Wikipedia</a>)</sup></p>\n<blockquote>\n<p><strong>Fig. 1, cont.</strong>: Except for <a href=\"https://en.wikipedia.org/wiki/Libration\" rel=\"noreferrer\">libration</a> effects, this results in the Moon keeping the same face turned towards the Earth, as seen in the figure\non the left. (The Moon is shown in polar view, and is not drawn to\nscale.) If the Moon were not spinning at all, it would alternately\nshow its near and far sides to the Earth while moving around our\nplanet in orbit, as shown in the figure on the right.</p>\n</blockquote>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<a href=\"https://web.archive.org/web/20201007012740/https://upload.wikimedia.org/wikipedia/commons/b/ba/Lunar_libration_with_phase_Oct_2007_450px.gif\" rel=\"noreferrer\"><img src=\"https://web.archive.org/web/20201007012740/https://upload.wikimedia.org/wikipedia/commons/b/ba/Lunar_libration_with_phase_Oct_2007_450px.gif\" alt=\"Tidal locking of the Moon with the Earth\" /></a></p>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<sup><strong>Fig. 2</strong>: Lunar librations in latitude and longitude over a period of one month (Source: <a href=\"https://en.wikipedia.org/wiki/File:Lunar_libration_with_phase_Oct_2007_450px.gif\" rel=\"noreferrer\">Wikipedia</a>)</sup></p>\n<blockquote>\n<p>Libration is manifested as a slow rocking back and forth of the Moon\nas viewed from Earth, permitting an observer to see slightly different\nhalves of the surface at different times.</p>\n<p>There are three types of lunar libration:</p>\n<ul>\n<li><p><strong>Libration in longitude</strong> results from the eccentricity\nof the Moon's orbit around Earth; the Moon's rotation sometimes leads\nand sometimes lags its orbital position.</p>\n</li>\n<li><p><strong>Libration in latitude</strong> results\nfrom a slight inclination between the Moon's axis of rotation and the\nnormal to the plane of its orbit around Earth. Its origin is analogous\nto how the seasons arise from Earth's revolution about the Sun.</p>\n</li>\n<li><p><strong><a href=\"https://en.wikipedia.org/wiki/Diurnal_motion\" rel=\"noreferrer\">Diurnal</a> libration</strong> is a small daily oscillation due to the Earth's\nrotation, which carries an observer first to one side and then to the\nother side of the straight line joining Earth's and the Moon's\ncenters, allowing the observer to look first around one side of the\nMoon and then around the other\u2014because the observer is on the surface\nof the Earth, not at its center.</p>\n</li>\n</ul>\n</blockquote>\n<p>All quotes and images from <a href=\"https://en.wikipedia.org/wiki/Tidal_locking\" rel=\"noreferrer\">Wikipedia on Tidal locking</a> and <a href=\"https://en.wikipedia.org/wiki/Libration\" rel=\"noreferrer\">Wikipedia on Libration</a>.</p>\n",
        "<p>The period of rotation of the moon is ~<a href=\"http://www.wolframalpha.com/input/?i=period%20of%20rotation%20of%20moon&amp;dataset=\">27.322 days</a>, and the period of revolution is also ~<a href=\"http://www.wolframalpha.com/input/?i=period%20of%20revolution%20of%20moon\">27.322</a>. This means that for every degree it turns around the Earth, it turns a degree around itself, so the same side always faces us.</p>\n\n<p>This is due to tidal forces coupling the various oscillators in the system (revolution of moon, orbit of moon, revolution of Earth). When oscillators are coupled, they have a tendency to settle to a state that is either in phase or 180 degrees out of phase*. Both cases give rise to tidal locking here.</p>\n\n<ul>\n<li>This is an experiment you can try out suspend  a pendulum from each end of a ruler, and give them a small phase difference. Over time, the phases will match.</li>\n</ul>\n",
        "<p>Black holes have so much gravity that <a href=\"https://astronomy.stackexchange.com/questions/7/why-cant-light-escape-from-a-black-hole/8#8\">even light can't escape from them</a>. If we can't see them, and the suck up all  electromagnetic radiation, then how can we find them? </p>\n",
        "<p>Primarily because of how the moon spins - it is spinning at <em>just</em> the right rate to keep us from seeing one side of it. Here's a handmade diagram to show what I mean:</p>\n\n<p><img src=\"https://i.stack.imgur.com/MDbbB.png\" alt=\"enter image description here\"></p>\n",
        "<p>According to <a href=\"http://solarsystem.nasa.gov/planets/profile.cfm?Object=Venus&amp;Display=Facts&amp;System=Metric\">this NASA overview</a>, the planet Venus is unique (amongst the major planets), Venus has a slow retrograde axial rotation, taking 243 Earth days to make one rotation (which is longer than its orbital revolution). </p>\n\n<p>What is the current accepted theory as to why (and how) Venus developed this anomalous slow retrograde axial rotation?</p>\n",
        "<p>Referring to <a href=\"https://astronomy.stackexchange.com/questions/7/why-cant-light-escape-from-a-black-hole\">this question</a>, is there any information that can leave black holes? Are they causing a permanent information loss in our Universe?</p>\n",
        "<p>So far, we don't have anywhere near enough detail to identify weather on planets in other star systems. We even have difficulty working out the size of some of them, so it may be a while till we can get a good idea as to weather.</p>\n\n<p>So the answer is going to be in our solar system. </p>\n\n<p>As for extremes, we have a couple of options:</p>\n\n<p><strong>WIND</strong></p>\n\n<p>Saturn and Neptune have the highest wind speeds, and as Neptune has the most extreme difference between East-West and West-East winds, I would be tempted to say it has the most extreme weather.</p>\n\n<p><img src=\"https://i.stack.imgur.com/SMw3x.png\" alt=\"enter image description here\"></p>\n\n<p>Taken from <a href=\"http://www.springerreference.com/docs/html/chapterdbid/366754.html\" rel=\"noreferrer\">http://www.springerreference.com/docs/html/chapterdbid/366754.html</a></p>\n\n<p><strong>TEMPERATURE</strong></p>\n\n<p>Pluto is incredibly cold, but it doesn't vary much, so should we call it an extreme? Mercury has a much more extreme range of temperatures. From sunside (over 400C) to coldside (almost -200C) gives a difference of 600 degrees Celsius!</p>\n",
        "<p>One way is by following <a href=\"http://en.wikipedia.org/wiki/Gamma-ray_burst\">Gamma Ray Bursts</a>. When a black hole feeds on surrounding gas or swallows a star that got too close, they often emit gamma ray bursts which are very energetic and easy to spot (although they don't last long).</p>\n\n<p>In the case of <a href=\"http://en.wikipedia.org/wiki/Supermassive_black_hole\">super massive blackholes</a>, they are seemingly at the center of every medium and large galaxy. It makes <em>where</em> to look rather easy.</p>\n",
        "",
        "Questions regarding the planet Venus, the second planet from the Sun.",
        "<p>Information cannot \"leave\" the black hole. There is no way (by our current framework of physics) that an entity inside the event horizon can send a signal out.</p>\n\n<p>However, entropy can leave. The black hole has entropy proportional to its surface area, and this roughly corresponds to \"the number of ways that black hole could have been created\". The surface area decreases due to <a href=\"http://enwp.org/Hawking_radiation\">Hawking radiation</a>, so it <em>can</em> release entropy back to the universe. Of course, the growth rate due to infalling mas is usually many orders of magnitude more than the shrinkage.</p>\n",
        "<p>From what I understand, the mass of a black hole should be nearly infinite, how much more <em>massive</em> can something get? </p>\n\n<ul>\n<li>Is the name to be literally interpreted such that a <em>Supermassive</em> Black Hole just has more <em>mass</em>?</li>\n<li>Or rather, is a Supermassive Black Hole just a regular Black Hole with nearly infinite mass that is larger in diameter?</li>\n<li>If the difference is in fact a change in diameter, how are the changes in size with the retention of the immense mass reflected in the Supermassive Black Hole's gravitational field?</li>\n</ul>\n",
        "<p>How to navigate with possible maximal precision using moon phases?</p>\n\n<p>The Moon is the brightest celestial body seen in the night sky, and it is possible to find even through moderate clouds. So it's a good natural object to use in navigation when a compass is not available. </p>\n\n<p>A full Moon is quite an easy case - it's directly on the opposite site from the Sun. However, in the other phases, are there tables or mnemotechnical methods allowing to determine the north based on moon shape, assuming the time is known? Are they different depending on geographical height? Is it possible to estimate both north and the time of the night, when only the geographical height is known?</p>\n",
        "<p><strong>A system projected into the sky</strong></p>\n\n<p>Pretend all the stars are painted on the inside of a large ball, and you are at the center of the ball. The imagined ball is called the Celestial Sphere. If the Earth wasn't blocking the lower half of your view, and the Sun wasn't making the blue sky so bright, you would be able to look at the stars in any direction.</p>\n\n<p>First, the rotation of the Earth causes the imagined ball of stars to appear to move around the sky. If you lay on your back, (in the norther hemisphere,) with your head to the north, the stars slowly slide by from left to right. There are two points however, where the stars don't appear to move: These two points are directly above the Earth's north and south poles. These two points, projected out into the sky are labeled the North, and South, Celestial Poles.</p>\n\n<p>Next, the Earth's equator is projected out into the sky and labeled the Celestial Equator.</p>\n\n<p>Finally, sorting out the east-west positioning, (ie left-right if you lay on your back, head to the north), requires an arbitrary selection: There are an infinite number of circles one can imagine drawing on the sky. (For example, small circles the size of the moon, and also many much bigger circles.) The largest circle you can draw is called a \"great circle\", from geometry. Point at the North Celestial Pole, (way above and behind your head if you face south in the northern hemisphere,) and draw a line straight south to the horizon, then down below your feet through the South celestial pole and back up to the North Celestial Pole. You have just drawn one Great Circle, through the Celestial Poles, all the way around the Celestial Sphere.</p>\n\n<p>But that Great Circle is just one of an infinite number of similar ones. One could start at the North Celestial Pole and draw a Great Circle a little to the left or the right. So astronomers have chosen one specific Great Circle and labeled one side of that circle as \"zero degrees\" -- or, \"we will start measuring angles from here.\"</p>\n\n<p><strong>So how do we use this system?</strong></p>\n\n<p>\"right ascension\" is measured rightward, (from your left to your right if you face south in the northern hemisphere,) from the zero-degrees half of that chosen great circle. So given a right ascension, one can find the corresponding half of a great circle. For a given right ascension, you have half of circle selected from the North Celestial Pole, to the South Celestial Pole. (This is called a line of equal longitude.)</p>\n\n<p>\"declination\" is measured from the Celestial Equator. The Celestial Equator cuts through the middle of your line of longitude. From the Celestial Equator it is 90\u00b0 northward(+) to the North Celestial Pole, and 90\u00b0 southward(-) to the South Celestial Pole. So we can measure from +90\u00b0 (northward) to -90\u00b0 (southward) along that line of longitude, from the Celestial Equator. (Don't be confused by \"positive declinations\"; 45\u00b0 of declination is northward from the Celestial Equator.)</p>\n\n<p>Notice that the system does not depend on where you are standing on Earth, nor on the time of day. If you have a Right Ascension and a Declination, you have an unambiguous spot specified on the Celestial Sphere. The system is actually very simple, but the rotation (time of day) of the Earth, and where you are geographically located needs to also be figured in.</p>\n\n<p><strong>What's over my head right now?</strong></p>\n\n<p>Face south, (if you're in the northern hemisphere.) What is your latitude -- geographically, how far north are you from the Earth's equator? If you are 40\u00b0 north, then Celestial declination of 40\u00b0 north is directly over your head. Declination of 50\u00b0 is 10\u00b0 further northward from directly over your head, etc. But for each declination, you have a circle of points in the sky that all have that same declination.  The circle is centered around the celestial poles.  As the earth turns it appears to slowly rotate overhead. Note: If you are at the equator, this circle is just the celestial equator, and it is a great circle.  As you approach either pole, the circle will get smaller.  The poles, this circle collapses to a point.  </p>\n\n<p>Right ascension you simply have to look up. That arbitrarily chosen, zero-degree line, appears to spin around the sky every day at the Earth rotates. Also, over the course of a year, the Earth's orbit about the sun makes an extra apparent turn of the sky. (What is overhead mid-winter, is directly under your feet mid-summer!) So there's an offset -- what right ascension is overhead <strong>on this date</strong> at midnight, and how far (in hours) are we from midnight right now? Combining those two you can figure out what Right Ascension is over head at any time, on any date.</p>\n\n<p><em>(potential editors: I've intentionally not used acronyms for NCP, RA, etc as that makes it more complicated for people learning this material.)</em></p>\n",
        "<p>Stellar mass black holes form from the collapse of massive stars at the end of their lives. You can then find them scattered throughout galaxies, just like you find massive stars. They typically have a mass a few times the mass of the sun.</p>\n\n<p>Supermassive black holes are found at the centers of galaxies. They typically have mass of millions of Suns. </p>\n\n<p>Recently they have started to discover <a href=\"http://en.wikipedia.org/wiki/Intermediate-mass_black_hole\">Intermediate Mass Black Holes</a> which blur the lines between a stellar black hole and supermassive black hole. The typically have a mass in the range 100 to one million solar masses.</p>\n",
        "<p>The mass of a black hole is not infinite. In fact, if a black hole is created that is big enough to survive evaporation, its mass will be its starting mass, plus any mass swallowed up, minus the radiation that leaves it.</p>\n\n<p>Which is why you hear phrases such as \"A black hole with ten times the mass of our sun\" or in the case of a supermassive black hole, \"...of millions of suns\"</p>\n",
        "<p>The planet Uranus is another solar system anomaly, where according to the <a href=\"http://solarsystem.nasa.gov/planets/profile.cfm?Object=Uranus&amp;Display=Facts&amp;System=Metric\" rel=\"noreferrer\">NASA profile</a> has an axial tilt of 97.8 degrees, also considered to be retrograde.  This NASA summary <a href=\"http://solarsystem.nasa.gov/planets/profile.cfm?Object=Uranus&amp;Display=OverviewLong\" rel=\"noreferrer\">\"Uranus\"</a> suggests the current theory of a large planet-sized impact earlier in its history.</p>\n\n<p>Does the planet-impact theory still hold true or have new accepted theories come to light?  </p>\n\n<p>Most of all, are there any results from any simulations available?</p>\n\n<p>A note, this is posted as a separate question to my other question <a href=\"https://astronomy.stackexchange.com/questions/26/what-is-the-current-accepted-theory-as-to-why-venus-has-a-slow-retrograde-rotati\">\"What is the current accepted theory as to why Venus has a slow retrograde rotation?\"</a> as the axial tilt is significantly different.</p>\n",
        "<p>Assume object A is moving through the space and is passing near the other object (B). Assume the gravitational influence of other objects can be ignored. How to find the equation describing the movement of the object B? </p>\n\n<p>There are 2 cases, object A is moving straightforward or it's moving on orbit (around other object). </p>\n\n<p>I think the problem is quite elementary, but I couldn't find anything that could help solve that problem using the physics on the level of basic university course (I've studied computer science, so I've got only 1 semester of physics, and basic mathematical knowledge - integrals, algebra etc.). </p>\n\n<p>I know the problem can be solved numerically, but I'm interested in finding the equation describing the movement. </p>\n",
        "<p>To add to John Conde's answer.  According to the NASA web page <a href=\"http://science.nasa.gov/astrophysics/focus-areas/black-holes/\">\"Black Holes\"</a>, detection of black holes can obviously not be performed by detection any form of electromagnetic radiation coming directly from it (hence, can not be 'seen').  </p>\n\n<p>The black hole is inferred by observing the interaction with surrounding matter, from the webpage:</p>\n\n<blockquote>\n  <p>We can, however, infer the presence of black holes and study them by detecting their effect on other matter nearby.</p>\n</blockquote>\n\n<p>This also includes detection of x-ray radiation that radiates from matter accelerating towards the black hole. Although this seems contradictory to my first paragraph - it needs to be noted that this is not directly from the black hole, rather from the interaction with matter accelerating towards it.</p>\n",
        "<p>The easiest way to think of equatorial coordinates is by extending lines of latitude/longitude (the geographic coordinate system we usually learn in school) out into space. The earth's equator becomes the celestial equator, and the north and south poles become the celestial north and south poles, respectively. By doing this you have a fairly simple way to describe the location of an object in space. </p>\n\n<p>Each location is described by a pair of coordinates: </p>\n\n<p>1) Declination (dec), which is measured in degrees (-90 for the south celestial pole, 0 for the celestial equator, and +90 for the north celestial pole). Partial degrees are usually described in terms of minutes (') and seconds (''). Think of declination as latitude.</p>\n\n<p>2) Right Ascension (RA), which is usually measured in hours, minutes, and seconds. Think of this as terrestrial longitude extended out into space, then measuring it in hours makes a bit more sense (time zones). You could just as easily measure it in degrees, too, where 1 hour is 15 degrees. RA is measured from the point where the sun crosses the celestial equator at the March equinox (located in Pisces).  </p>\n",
        "<p>What processes does a star undergo to become a pulsar? Does it take a very specific star with a certain set of qualities such as \"Just the right mass, diameter, and composition,\" or is it a freak accident that certain stars live out their remaining life as a pulsar?</p>\n",
        "<p>I'd say that <a href=\"http://en.wikipedia.org/wiki/HD_189733b\">HD 189733b</a> is a good candidate for the most extreme <em>known</em> weather on another planet (outside our Solar System).</p>\n\n<p>According to some recent <a href=\"http://www.space.com/22614-blue-alien-planet-glass-rain.html\">news accounts</a>, the atmospheric temperature is believed to be over 1000\u00b0 C, with 7000 kph winds. (For comparison to the data in Rory Alsop's answer, that's about 1900 meters per second.)</p>\n\n<p>And it rains molten glass. Sideways.</p>\n\n<p><strong>UPDATE :</strong> As Guillochon points out in a comment, <a href=\"http://en.wikipedia.org/wiki/HD_80606_b\">HD 80606 b</a> likely has even higher winds, though they're not continuous. It's a Jovian with an extremely eccentric orbit. Quoting the Wikipedia article:</p>\n\n<blockquote>\n  <p>Computer models predict the planet heats up 555 \u00b0C (1,000 \u00b0F) in just\n  a matter of hours triggering \"shock wave storms\" with winds that move\n  faster than the speed of sound, at 3 miles per second.</p>\n</blockquote>\n\n<p>which, in civilized units, is about 4800 meters/second. Probably no molten glass rain, though, so it's not clear that it's more \"extreme\".</p>\n",
        "<p>It's generally dictated by how massive the star is. Remember what a pulsar is, it's a very rapidly rotating, highly magnetized neutron star.</p>\n\n<p><img src=\"https://imagine.gsfc.nasa.gov/Images/basic/xray/pulsar.gif\" alt=\"Pulsar\"></p>\n\n<p>Neutron stars are a category of objects which have masses between 1.4 and 3.2 solar masses. This is the end stage of stars which are not massive enough to form black holes (they're held up by neutron degeneracy pressure), but are massive enough to overcome electron degeneracy pressure (which is what prevents white dwarves from further gravitational collapse). </p>\n",
        "<p>In theory one should just be able to determine the difference between the spectra during the star's eclipse of the exoplanet (starlight alone) and the spectra of the star and exoplanet together, but in reality equipment is not precise enough for this. To remedy this problem, the analysis is integrated over many eclipses. Some other calibrations are made as well which you can read more about in the paper <a href=\"http://arxiv.org/pdf/astro-ph/0702494.pdf\" rel=\"nofollow noreferrer\">A <em>Spitzer</em> Spectrum of the Exoplanet HD 189733b</a>. This is called occultation spectroscopy.</p>\n<p>There's another method used as well called transmission spectroscopy, which <a href=\"https://exoplanets.nasa.gov/resources/297/a-planets-transmission-spectrum/\" rel=\"nofollow noreferrer\">detects the change in light as the exoplanet passes in front of its star</a>. You can read more about that in this paper: <a href=\"https://iopscience.iop.org/article/10.1088/0004-637X/774/2/95/meta\" rel=\"nofollow noreferrer\">Infrared transmission spectroscopy of the exoplanets HD 209458b and XO-1b using the wide field Camera-3 on the Hubble Space Telescope</a>.</p>\n",
        "<p>The equatorial coordinate system is very similar to the system used on a globe or on maps. To specify a point on a sphere or a globe you need only two numbers. These are the longitudes and latitudes.</p>\n\n<p>On a globe of the earth you have longitudes from -180\u00ba to +180\u00ba and latitudes from -90\u00ba to +90\u00ba. The south pole lies at -90\u00ba latitude, the north pole at +90\u00ba latitude.</p>\n\n<p>The sky uses the same system, projected onto the imaginary celestial sphere. The sky's equator is at the same position as the earth's equator. Only projected onto the (infinitely large) sky sphere. You can find lots of <a href=\"http://astronomy.swin.edu.au/cosmos/E/Equatorial+Coordinate+System\">very nice pictures</a> of this on the web.</p>\n\n<p>However, since the earth rotates, the sky's coordinate system would rotate also, if it only were a synchronized projection. So every star would have a coordinate that depended on the time of day! </p>\n\n<p>To solve this, the equatorial coordinate system is fixed on the equinox points. Since the earth is tilted, the eclipitc (i.e. the earth's orbit around the sun) has two intersections with the sky's equator. These are the equinox points. The sun will be located there during the days of spring and autumn when day and night are of equal length. These points on the sky sphere are relatively fixed and well suited for pinning down the coordinate system. </p>\n\n<p>The sky's coordinate system is not using the degree notation for both longitude and latitude. Instead we use the terms Right Acension (i.e. longitude), which goes from 0h to 24h, similar to a day on earth. And the other is Declination (i.e. latitude), which goes from -90\u00ba to +90\u00ba. This is similar to the earth's traditional coordinate system.</p>\n\n<p>So every fixed star can be assigned a coordinate in the sky which is independent of the time of day or year. For example, the star Sirius (\u03b1 CMa) has the following coordinates:</p>\n\n<p>RA 06h 45m 08.9173s Dec \u221216\u00b0 42\u2032 58.017\u2033</p>\n\n<p>These can be programmed into computerized telescope mounts, which can then find and track the star as it moves with the earth's rotation.</p>\n\n<p>This is a rather simplified explanation. One should read up on equatorial mounts for telescopes, which utilize this coordinate system in a very elegant manner.</p>\n",
        "<p>In a museum in Lviv, I saw a pocket cellular clock. I don't have a photo, but it was a small disc that had 2 or 3 filaments in it which were pointed at the stars (one of them was Andromeda, I think). Through analyzing the position of the stars it was possible to determine the time of the night. I'm not sure if knowing the day of the year was promised.</p>\n\n<p>I couldn't find the information about the way the clock was used. Does anyone know how such device was used?</p>\n",
        "",
        "Questions regarding a layer of gasses surrounding a celestial object.",
        "<p>An orbit is the trajectory a body follows due to the gravitational field of another nearby object. \nMost often, an orbit follows a closed path and is periodical, but the term can also refer to non-repeating trajectories. </p>\n\n<p>Examples of orbits include the path of the Moon around the Earth, the path of the Earth around the Sun, or the path of two stars in a binary pair around their common center of mass.</p>\n",
        "Questions regarding an object 'falling around' another object, due to a combination of gravity and momentum.\r\n",
        "<p>Given that some exoplanets, particular <a href=\"http://science.nasa.gov/science-news/science-at-nasa/2013/17aug_hotjupiters/\">\"Hot Jupiters\"</a>, orbit very closely to their parent star, how hot can these planets become?</p>\n\n<p>What is the hottest exoplanet discovered so far?</p>\n",
        "<p>The temperature of an exoplanet is dependent on a number of factors, including:</p>\n\n<ul>\n<li><p>The distance between the exoplanet and the parent star.</p></li>\n<li><p>The type (energy output) of the parent star.</p></li>\n<li><p>The ability of the exoplanet's atmosphere to distribute the heat energy.</p></li>\n</ul>\n\n<p>Recent discoveries, such as reported in the article <a href=\"http://www.space.com/3781-sizzling-planet-stars-cool.html\">\"Sizzling Planet Makes Some Stars Look Cool\"</a> (Than, 2007), have found that some exoplanets are hotter than some types of stars.</p>\n\n<p>For example, the exoplanet <a href=\"http://www.nasa.gov/mission_pages/spitzer/multimedia/F-Black-artist.html\"> HD 149026b </a> has a star-facing side of over 2000C (3700F), this planet reflects so little light that it would appear like a \"glowing piece of charcoal\". It is believed (from the article) that the planet is tidally locked and the 'dark side' of the planet is believed to be substantially cooler.</p>\n",
        "<p>The device that you saw is called a nocturnal. It calculates the local time based on the month of the year and the position of Polaris and one or more other stars.</p>\n\n<p>Since stars change position throughout the night, they can be used to determine time; but the positions of stars change throughout the year, so the input of the month of the year is needed. Polaris is used as a relatively fixed reference point.</p>\n\n<p><strong>More information</strong>:</p>\n\n<p><a href=\"http://en.wikipedia.org/wiki/Nocturnal_%28instrument%29\">Nocturnal (instrument) - Wikipedia</a></p>\n"
    ],
    "ai": [
        "<p>What does \"backprop\" mean? Is the \"backprop\" term basically the same as \"backpropagation\" or does it have a different meaning?</p>\n",
        "<p>Does increasing the noise in data help to improve the learning ability of a network? Does it make any difference or does it depend on the problem being solved? How is it affect the generalization process overall?</p>\n",
        "<p>\"Backprop\" is the same as \"backpropagation\": it's just a shorter way to say it. It is sometimes abbreviated as \"BP\".</p>\n",
        "<p>When you're writing your algorithm, how do you know how many neurons you need per single layer? Are there any methods for finding the optimal number of them, or is it a rule of thumb?</p>\n",
        "<p>Given the following definition of an intelligent agent (taken from a <a href=\"http://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence#Intelligent_agent_definition\" rel=\"nofollow noreferrer\">Wikipedia article</a>)</p>\n\n<blockquote>\n  <p>If an agent acts so as to maximize the expected value of a performance measure based on past experience and knowledge then it is intelligent</p>\n</blockquote>\n\n<p>and given that we, humans, all make mistakes, which means that we are not maximizing the expected value of a performance measure, then does this imply that humans are not intelligent? </p>\n",
        "<p>This <a href=\"https://www.independent.co.uk/life-style/gadgets-and-tech/news/stephen-hawking-artificial-intelligence-could-wipe-out-humanity-when-it-gets-too-clever-humans-could-become-ants-being-stepped-a6686496.html\" rel=\"nofollow noreferrer\">quote by Stephen Hawking</a> has been in headlines for quite some time:</p>\n<blockquote>\n<p>Artificial Intelligence could wipe out humanity when it gets too clever as humans will be like ants.</p>\n</blockquote>\n<p>Why does he say this? To put it simply: what are the possible threats from AI (that Stephen Hawking is worried about)? If we know that AI is so dangerous, why are we still promoting it? Why is it not banned?</p>\n<p>What are the adverse consequences of the so-called <a href=\"https://en.wikipedia.org/wiki/Technological_singularity\" rel=\"nofollow noreferrer\">Technological Singularity</a>?</p>\n",
        "<p>Noise in the data, to a reasonable amount, may help the network to generalize better. Sometimes, it has the opposite effect. It partly depends on the kind of noise (\"true\" vs. artificial).</p>\n\n<p>The <a href=\"ftp://ftp.sas.com/pub/neural/FAQ3.html#A_noise\" rel=\"nofollow noreferrer\">AI FAQ on ANN</a> gives a good overview. Excerpt:</p>\n\n<blockquote>\n  <p>Noise in the actual data is never a good thing, since it limits the accuracy of generalization that can be achieved no matter how extensive the training set is. On the other hand, injecting artificial noise (jitter) into the inputs during training is one of several ways to improve generalization for smooth functions when you have a small training set.</p>\n</blockquote>\n\n<p>In some field, such as computer vision, it's common to increase the size of the training set by copying some samples and adding some noises or other transformation.</p>\n",
        "<p>I'm new to A.I. and I'd like to know in simple words, what is the fuzzy logic concept? How does it help, and when is it used?</p>\n",
        "<p>We typically think of machine learning models as modeling two different parts of the training data--the underlying generalizable truth (the signal), and the randomness specific to that dataset (the noise).</p>\n\n<p>Fitting both of those parts increases training set accuracy, but fitting the signal also increases test set accuracy (and real-world performance) while fitting the noise decreases both. So we use things like regularization and dropout and similar techniques in order to make it harder to fit the noise, and so more likely to fit the signal.</p>\n\n<p>Just increasing the amount of noise in the training data is one such approach, but seems unlikely to be as useful. Compare random jitter to adversarial boosting, for example; the first will slowly and indirectly improve robustness whereas the latter will dramatically and directly improve it.</p>\n",
        "<p>There is no direct way to find the optimal number of them: people empirically try and see (e.g., using cross-validation). The most common search techniques are random, manual, and grid searches. </p>\n\n<p>There exist more advanced techniques such as Gaussian processes, e.g. <em><a href=\"http://arxiv.org/abs/1609.08703\" rel=\"noreferrer\">Optimizing Neural Network Hyperparameters with Gaussian Processes for Dialog Act Classification</a>, IEEE SLT 2016</em>.</p>\n",
        "<p>In particular, an embedded computer (with limited resources) analyzes live video stream from a traffic camera, trying to pick good frames that contain license plate numbers of passing cars. Once a plate is located, the frame is handed over to an OCR library to extract the registration and use it further.</p>\n\n<p>In my country two types of license plates are in common use - rectangular (the typical) and square - actually, somewhat rectangular but \"higher than wider\", with the registration split over two rows.</p>\n\n<p>(there are some more types, but let us disregard them; they are a small percent and usually belong to vehicles that lie outside our interest.)</p>\n\n<p>Due to the limited resources and need for rapid, real-time processing, the maximum size of the network (number of cells and connections) the system can handle is fixed.</p>\n\n<p>Would it be better to split this into two smaller networks, each recognizing one type of registration plates, or will the larger single network handle the two types better?</p>\n",
        "<p>The <a href=\"https://en.wikipedia.org/wiki/Turing_test\">Turing Test</a> was the first test of artificial intelligence and is now a bit outdated. The <a href=\"https://en.wikipedia.org/wiki/Turing_test#Total_Turing_test\">Total Turing Test</a> aims to be a more modern test which requires a much more sophisticated system. What techniques can we use to identify an artificial intelligence (weak AI) and an <a href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\">artificial general intelligence</a> (strong AI)?</p>\n",
        "<p>What is <a href=\"https://en.wikipedia.org/wiki/Early_stopping\" rel=\"nofollow noreferrer\">early stopping</a> in machine learning and, in general, artificial intelligence? What are the advantages of using this method? How does it help exactly?</p>\n\n<p>I'd be interested in perspectives and links to recent research.</p>\n",
        "<p>I've heard the idea of the technological singularity, what is it and how does it relate to Artificial Intelligence? Is this the theoretical point where Artificial Intelligence machines have progressed to the point where they grow and learn on their own beyond what humans can do and their growth takes off?  How would we know when we reach this point?</p>\n",
        "<blockquote>\n  <p>To put it simply in layman terms, what are the possible threats from AI? </p>\n</blockquote>\n\n<p>Currently, there are no threat. </p>\n\n<p>The threat comes if humans create a so-called ultraintelligent machine, a machine that can surpass all intellectual activities by any human. This would be the last invention man would need to do, since this machine is better in inventing machines than humans are (since that is an intellectual activity).  However, this could cause the machine to invent machines that can destruct humans, and we can't stop them because they are so much smarter than we are.</p>\n\n<p>This is all hypothetical, no one has even a clue of what an ultraintelligent machine looks like. </p>\n\n<blockquote>\n  <p>If we know that AI is so dangerous why are we still promoting it? Why is it not banned?</p>\n</blockquote>\n\n<p>As I said before, the existence of a ultraintelligent machine is hypothetical. Artificial Intelligence has lots of useful applications (more than this answer can contain), and if we develop it, we get even more useful applications. We just have to be careful that the machines won't overtake us. </p>\n",
        "<p>Because he did not yet know how far away current AI is... Working in an media AI lab, I get this question a lot. But really... we are still a long way from this. The robots still do everything we detailledly describe them to do. Instead of seeing the robot as intelligent, I would look to the human programmer for where the creativity really happens.</p>\n",
        "<p>It rather depends on how one defines several of the terms used. For example:</p>\n\n<ul>\n<li>Whether the term \"expected\" is interpreted in a formal (i.e.\nstatistical) sense.  </li>\n<li>Whether it's assumed that humans have any kind of utilitarian\n\"performance measure\".</li>\n</ul>\n\n<p>The motivation for this description of \"agent\" arose from a desire to have a quantitative model - it's not clear that such a model is a good fit for human cognition.</p>\n\n<p>However, there are alternative definitions of agents, for example the <a href=\"https://en.wikipedia.org/wiki/Belief%E2%80%93desire%E2%80%93intention_software_model\" rel=\"nofollow noreferrer\">BDI model</a>, which are rather more open-ended and hence more obviously applicable to humans.</p>\n",
        "<p>I'm worrying that my neural network has become too complex. I don't want to end up with half of the neural network doing nothing but just take up space and resources.</p>\n<p>So, what are the techniques for detecting and preventing overfitting, to avoid such problems?</p>\n",
        "<p>It's not just Hawking, you hear variations on this refrain from a lot of people.  And given that they're mostly very smart, well educated, well informed people (Elon Musk is another, for example), it probably shouldn't be dismissed out of hand.</p>\n\n<p>Anyway, the basic idea seems to be this: If we create \"real\" artificial intelligence, at some point, it will be able to improve itself, which improves it's ability to improve itself, which means it can improve it's ability to improve itself even more, and so on... a runaway cascade leading to \"superhuman intelligence\".  That is to say, leading to something that more intelligent than we area.</p>\n\n<p>So what happens if there is an entity on this planet which is literally more intelligent than us (humans)? Would it be a threat to us?  Well, it certainly seems reasonable to speculate that it <em>could</em> be so.   OTOH, we have no particular reason, right now, to think that it <em>will</em> be so. </p>\n\n<p>So it seems that Hawking, Musk, etc. are just coming down on the more cautious / fearful side of things.  Since we don't <em>know</em> if a superhuman AI will be dangerous or not, and given that it could be unstoppable if it were to become malicious (remember, it's smarter than we are!), it's a reasonable thing to take under consideration.</p>\n\n<p>Eliezer Yudkowsky has also written quite a bit on this subject, including come up with the famous \"AI Box\" experiment.  I think anybody interested in this topic should read some of his material.</p>\n\n<p><a href=\"http://www.yudkowsky.net/singularity/aibox/\" rel=\"noreferrer\">http://www.yudkowsky.net/singularity/aibox/</a></p>\n",
        "<p>As Andrew Ng <a href=\"http://www.theregister.co.uk/2015/03/19/andrew_ng_baidu_ai/\" rel=\"nofollow noreferrer\">said</a>, worrying about such threat from AI is like worrying about of overpopulation on Mars. It is science fiction. </p>\n\n<p><a href=\"https://i.stack.imgur.com/m6jnl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/m6jnl.png\" alt=\"enter image description here\"></a></p>\n\n<p>That being said, given the rise of (much weaker) robots and other (semi-)autonomous agents, the fields of the law and ethics are increasingly incorporating them, e.g. see <a href=\"https://en.wikipedia.org/wiki/Roboethics\" rel=\"nofollow noreferrer\">Roboethics</a>.</p>\n",
        "<p>He says this because it can happen. If something becomes smarter than us, why would it continue to serve us? The worst case scenario is that it takes over all manufacturing processes and consumes all matter to convert it into material capable of computation, extending outward infinitely until all matter is consumed.</p>\n\n<p>We know that AI is dangerous but it doesn't matter because most people don't believe in it. It goes against every comfort religion has to offer. Man is the end-all-be-all of the universe and if that fact is disputed, people will feel out of place and purposeless.</p>\n\n<p>The fact is most people just don't acknowledge it's possible, or that it will happen in our lifetimes, even though many reputable AI experts put the occurrence of the singularity within two decades. If people truly acknowledged that AI that was smarter than them was possible, wouldn't they be living differently? Wouldn't they be looking to do things that they enjoy, knowing that whatever it is they do that they dread will be automated? Wouldn't everyone be calling for a universal basic income?</p>\n\n<p>The other reason we don't ban it is because its promise is so great. One researcher could be augmented by 1,000 digital research assistants. All manual labor could be automated. For the first time, technology offers us real freedom to do whatever we please.</p>\n\n<p>But even in this best case scenario where it doesn't overtake us, humans still have to adapt and alter their economic system to one where labor isn't necessary. Otherwise, those who aren't technically-trained will starve and revolt.</p>\n",
        "<p>There are a number of long resources to answer this sort of question: consider Stuart Armstrong's book <a href=\"http://rads.stackoverflow.com/amzn/click/B00IB4N4KU\" rel=\"nofollow\">Smarter Than Us</a>, Nick Bostrom's book <a href=\"http://rads.stackoverflow.com/amzn/click/B00LOOCGB2\" rel=\"nofollow\">Superintelligence</a>, which grew out of this <a href=\"http://www.nickbostrom.com/views/superintelligence.pdf\" rel=\"nofollow\">edge.org answer</a>, <a href=\"http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html\" rel=\"nofollow\">Tim Urban's explanation</a>, or <a href=\"https://aisafety.wordpress.com/\" rel=\"nofollow\">Michael Cohen's explanation</a>.</p>\n\n<p>But here's my (somewhat shorter) answer: intelligence is all about decision-making, and we don't have any reason to believe that humans are anywhere near close to being the best possible at decision-making. Once we are able to build an AI AI researcher (that is, a computer that knows how to make computers better at thinking), the economic and military relevance of humans will rapidly disappear as any decision that could be made by a human could be made better by a computer. (Why have human generals instead of robot generals, human engineers instead of robot engineers, and so on.)</p>\n\n<p>This isn't necessarily a catastrophe. If the Vulcans showed up tomorrow and brought better decision-making to Earth, we could avoid a lot of misery. The hard part is making sure that what we get are Vulcans who want us around and happy, instead of something that doesn't share our values.</p>\n",
        "<p>I've seen emotional intelligence defined as the capacity to be aware of, control, and express one's emotions, and to handle interpersonal relationships judiciously and empathetically.  </p>\n\n<ol>\n<li><p>What are some strategies for artificial intelligence to begin to tackle this problem and develop emotional intelligence for computers?  </p></li>\n<li><p>Are there examples where this is already happening to a degree today?  </p></li>\n<li><p>Wouldn't a computer that passes a Turing test necessarily express emotional intelligence or it would be seen as an obvious computer?  </p>\n\n<p>Perhaps that is why early programs that pass the test represented young people, who presumably have lower emotional intelligence.</p></li>\n</ol>\n",
        "<p>The problem of the Turing Test is that it tests the machines ability to resemble humans. Not necessarily every form of AI has to resemble humans. This makes the Turing Test less reliable. However, it is still useful since it is an actual test. It is also noteworthy that there is a prize for passing or coming closest to passing the Turing Test, the <a href=\"https://en.wikipedia.org/wiki/Loebner_Prize\">Loebner Prize</a>.</p>\n\n<p>The intelligent agent definition of intelligence states that an agent is intelligent if it acts so to maximize the expected value of a performance measure based on past experience and knowledge. (paraphrased from <a href=\"http://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence#Intelligent_agent_definition\">Wikipedia</a>). This definition is used more often and does not depend on the ability to resemble humans. However, it is harder to test this. </p>\n",
        "<p>Since human intelligence presumably is a function of a natural genetic algorithm in nature, is using a genetic algorithm in a computer an example of artificial intelligence? If not, how do they differ? Or perhaps some are and some are not expressing artificial intelligence depending upon the scale of the algorithm and what it evolves into?</p>\n",
        "",
        "",
        "<p>It's analogous to analogue versus digital, or the many shades of gray in between black and white: when evaluating the truthiness of a result, in binary boolean it's either true or false (0 or 1), but when utilizing fuzzy logic, it's an estimated probability between 0 and 1 (such as 0.75 being mostly probably true). It's useful for making calculated decisions when all information needed isn't necessarily available.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Fuzzy_logic\" rel=\"noreferrer\">Wikipedia has a fantastic page for this</a>.</p>\n",
        "<p><em>As complexity rises, precise statements lose meaning and meaningful statements lose precision.</em> ( Lofti Zadeh ).</p>\n\n<p>Fuzzy logic deals with reasoning that is approximate rather than fixed and exact. This may make the reasoning more meaningful for a human:</p>\n\n<p><a href=\"https://i.stack.imgur.com/xdHPJ.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/xdHPJ.png\" alt=\"Precision and significance - comic\"></a></p>\n\n<hr>\n\n<p>Fuzzy logic is an extension of Boolean logic by Lotfi Zadeh in 1965 based on the\nmathematical theory of fuzzy sets, which is a generalization of the classical set theory.\nBy introducing the notion of <em>degree in the verification</em> of a condition, thus enabling a\ncondition to be in a state other than true or false, fuzzy logic provides a very valuable\nflexibility for reasoning, which makes it possible to take into account inaccuracies and\nuncertainties.</p>\n\n<p>One advantage of fuzzy logic in order to formalize human reasoning is that the rules\nare set in natural language. For example, here are some rules of conduct that a driver\nfollows, assuming that he does not want to lose his driver\u2019s licence:</p>\n\n<p><a href=\"https://i.stack.imgur.com/TM2UE.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/TM2UE.png\" alt=\"Fuzzy logic decision table\"></a></p>\n\n<p>Intuitively, it thus seems that the input variables like in this example are approximately\nappreciated by the brain, such as the degree of verification of a condition in fuzzy\nlogic.</p>\n\n<hr>\n\n<p>I've written a short <a href=\"https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=kz2aIc8AAAAJ&amp;citation_for_view=kz2aIc8AAAAJ:eQOLeE2rZwMC\" rel=\"noreferrer\">introduction to fuzzy logic</a> that goes into a bit more details but should be very accessible.</p>\n",
        "<p>The concept of \"the singularity\" is when machines outsmart the humans. Although Stephen Hawking opinion is that this situation is inevitable, but I think it'll be very difficult to reach that point, because every A.I. algorithm needs to be programmed by humans, therefore it would be always more limited than its creator.</p>\n\n<p>We would probably know when that point when humanity will lose control over Artificial Intelligence where super-smart AI would be in competition with humans and maybe creating more sophisticated intelligent beings occurred, but currently, it's more like science fiction (aka <a href=\"https://en.wikipedia.org/wiki/Skynet_(Terminator)\" rel=\"nofollow noreferrer\">Terminator's Skynet</a>).</p>\n\n<p>The risk could involve killing people (like self-flying war <em>drones</em> making their own decision), destroying countries or even the whole planet (like A.I. connected to the nuclear weapons (aka <a href=\"https://en.wikipedia.org/wiki/WarGames\" rel=\"nofollow noreferrer\">WarGames</a> movie), but it doesn't prove the point that the machines would be smarter than humans.</p>\n",
        "<p>These two terms seem to be related, especially in their application in computer science and software engineering.</p>\n<ul>\n<li>Is one a subset of another?</li>\n<li>Is one a tool used to build a system for the other?</li>\n<li>What are their differences and why are they significant?</li>\n</ul>\n",
        "<p>What aspects of quantum computers, if any, can help to further develop Artificial Intelligence?</p>\n",
        "<p>I believe a Markov chain is a sequence of events where each subsequent event depends probabilistically on the current event.  What are examples of the application of a Markov chain and can it be used to create artificial intelligence?  Would a genetic algorithm be an example of a Markov chain since each generation depends upon the state of the prior generation?</p>\n",
        "<p>This is probably more a question of philosophy than anything. In terms of how things are commonly defined, I'll say \"yes, genetic algorithms are part of AI\".  If you pick up a comprehensive book on artificial intelligence, there will probably be a chapter on genetic algorithms (or more broadly, evolutionary algorithms). </p>\n\n<p>One area that has been extensively studied in the past is the idea of using genetic algorithms to train neural networks.  I don't know if people are still actively researching this topic or not, but it at least illustrates that GA's are part of the overall rubric of AI in one regard.</p>\n",
        "<p>The rhetorical point of the Turing Test is that it places the 'test' for 'humanity' in <em>observable outcomes</em>, instead of in <em>internal components</em>. If you would behave the same in interacting with an AI as you would with a person, how could <em>you</em> know the difference between them?</p>\n\n<p>But that doesn't mean it's reliable, because intelligence has many different components and there are many sorts of intellectual tasks. The Turing Test, in some respects, is about the reaction of people to behavior, which is not at all reliable--remember that many people thought <a href=\"https://en.wikipedia.org/wiki/ELIZA\">ELIZA</a>, a very simple chatbot, was an excellent listener and got deeply emotionally involved very quickly. It calls to mind the <a href=\"https://www.youtube.com/watch?v=dBqhIVyfsRg\">Ikea commercial about throwing out a lamp</a>, where the emotional attachment comes <em>from the human viewer</em> (and the music), rather than from the lamp.</p>\n\n<p>Turing tests for specific economic activities are much more practically interesting--if one can write an AI that replaces an Uber driver, for example, what that will imply is much clearer than if someone can create a conversational chatbot.</p>\n",
        "<p>What purpose does the \"dropout\" method serve and how does it improve the overall performance of the neural network?</p>\n",
        "<p>Can an AI program have an IQ? In other words, can the IQ of an AI program be measured? Like how humans can do an IQ test.</p>\n",
        "<p>Why would anybody want to use \"hidden layers\"? How do they enhance the learning ability of the network in comparison to the network which doesn't have them (linear models)?</p>\n",
        "<p>Fuzzy logic is based on regular boolean logic. Boolean logic means you are working with truth values of either true or false (or 1 or 0 if you prefer). Fuzzy logic is the same apart from you can have truth values that are in-between true and false, which is to say, you are working with any number between 0 (inclusive) and 1 (inclusive). The fact that you can have a 'partially true and partially false' truth value is where the word &quot;fuzzy&quot; comes from. Natural languages often use fuzzy logic like &quot;that balloon is red&quot; meaning that balloon could be any colour that is similar enough to red, or &quot;the shower is warm&quot;. Here is a rough diagram for how &quot;the temperature of the shower is warm&quot; could be represented in terms of fuzzy logic (the y axis being the truth value and the x-axis being the temperature):</p>\n<p><a href=\"https://i.stack.imgur.com/G7szY.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/G7szY.png\" alt=\"y-axis=truth value of statement about temperature, x-axis=temperature\" /></a></p>\n<p>Fuzzy logic can be applied to boolean operations such as <strong>and</strong>, <strong>or</strong>, and <strong>not</strong>. Note that you can define the fuzzy logic operations in different ways. One way is with the min and max functions which return the lessermost and greatermost values of the two values inputted respectively. This would work as such:</p>\n<pre><code>A and B = min(A,B)\nA or B  = max(A,B)\nnot A   = 1-A\n(where A and B are real values from 0 (inclusive) to 1 (inclusive))\n</code></pre>\n<p>When defined like this they are called the <strong>Zadeh operators</strong>.</p>\n<p>Another way would be to define <strong>and</strong> as the first argument times the second argument, which yields different outputs for the same inputs as the Zadeh <strong>and</strong> operator (<code>min(0.5,0.5)=0.5, 0.5*0.5=0.25</code>). Then other operators are derived based on the <strong>and</strong> and <strong>not</strong> operators. This would work as such:</p>\n<pre><code>A and B = A*B\nnot A = 1-A\nA or B = not ((not A) and (not B)) = 1-((1-A)*(1-B)) = 1-(1-A)*(1-B)\n(where A and B are real values from 0 (inclusive) to 1 (inclusive))\n</code></pre>\n<p>You can then use the three &quot;basic fuzzy logic operations&quot; to build all other &quot;fuzzy logic operations&quot;, just like you can use the three &quot;basic boolean operations&quot; to build all other &quot;boolean logic operations&quot;.</p>\n<p>Note that the latter definition of the three basic operations is more in line with probability theory, so could be considered the more natural choice.</p>\n<p>Sources:\n<a href=\"https://en.wikipedia.org/wiki/Fuzzy_logic\" rel=\"nofollow noreferrer\">Fuzzy logic wikipedia</a>,\n<a href=\"https://en.wikipedia.org/wiki/Boolean_algebra\" rel=\"nofollow noreferrer\">Boolean algebra wikipedia</a>,\n<a href=\"https://www.youtube.com/watch?v=r804UF8Ia4c\" rel=\"nofollow noreferrer\">Explanation of fuzzy logic on Youtube</a></p>\n<p>Note: if anyone could suggest some more reliable sources in the comments, I will happily add them to the list (I understand that the current ones aren't too reliable).</p>\n",
        "<p>Dropout means that every individual data point is only used to fit a random subset of the neurons. This is done to make the neural network more like an ensemble model.</p>\n\n<p>That is, just as a random forest is averaging together the results of many individual decision trees, you can see a neural network trained using dropout as averaging together the results of many individual neural networks (with 'results' understood to mean activations at every layer, rather than just the output layer).</p>\n",
        "<p>The <a href=\"https://en.wikipedia.org/wiki/Technological_singularity\" rel=\"nofollow noreferrer\">technological singularity</a> is a theoretical point in time at which a <em>self-improving</em> <a href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\" rel=\"nofollow noreferrer\">artificial general intelligence</a> becomes able to understand and manipulate concepts outside of the human brain's range, that is, the moment when it can understand things humans, by biological design, can't.</p>\n<p>The fuzziness about the singularity comes from the fact that, from the singularity onwards, history is effectively <em>unpredictable</em>. Humankind would be unable to predict any future events, or explain any present events, as science itself becomes incapable of describing machine-triggered events. Essentially, machines would think of us the same way we think of ants. Thus, we can make no predictions past the singularity. Furthermore, as a logical consequence, we'd be unable to define the point at which the singularity may occur at all, or even recognize it when it happens.</p>\n<p>However, in order for the singularity to take place, AGI needs to be developed, and <a href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence#Feasibility\" rel=\"nofollow noreferrer\">whether that is possible is quite a hot debate</a> right now. Moreover, an algorithm that creates <em>superhuman intelligence</em> (or <a href=\"https://en.wikipedia.org/wiki/Superintelligence\" rel=\"nofollow noreferrer\"><em>superintelligence</em></a>) out of bits and bytes would have to be designed. By definition, a human programmer wouldn't be able to do such a thing, as his/her brain would need to be able to comprehend concepts beyond its range. There is also the argument that an <a href=\"https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion\" rel=\"nofollow noreferrer\"><em>intelligence explosion</em></a> (the mechanism by which a technological singularity would theoretically be formed) would be impossible due to the difficulty of the design challenge of making itself more intelligent, getting larger proportionally to its intelligence, and that the difficulty of the design itself may overtake the intelligence required to solve the said challenge.</p>\n<p>Also, there are related theories involving <a href=\"https://en.wikipedia.org/wiki/AI_takeover\" rel=\"nofollow noreferrer\"><em>machines taking over humankind</em></a> and all of that sci-fi narrative. However, that's unlikely to happen, if <a href=\"https://en.wikipedia.org/wiki/Three_Laws_of_Robotics\" rel=\"nofollow noreferrer\">Asimov's laws</a> are followed appropriately. <a href=\"https://www.youtube.com/watch?app=desktop&amp;v=7PKx3kS7f4A\" rel=\"nofollow noreferrer\">Even if Asimov's laws were not enough</a>, a series of constraints would still be necessary in order to avoid the misuse of AGI by misintentioned individuals, and Asimov's laws are the nearest we have to that.</p>\n",
        "<p>When did research into Artificial Intelligence first begin?  Was it called Artificial Intelligence then or was there another name?</p>\n",
        "<p>The notion of genetics used in Genetic Algorithms (GAs) is a <em>very</em> stripped down version relative to genetics in nature, essentially consisting of a population of 'genes' (representing solutions to some predefined problem) subject to `survival of the fittest' during iterated application of recombination and mutation.</p>\n\n<p>Nowadays, the term 'Computational Intelligence' (CI) tends to be used to describe computational techniques intended to produce `the appearance of intelligence by <em>any</em> computational means', rather than specifically attempting to mimic the mechanisms that are believed to give rise to human (or animal) intelligence.</p>\n\n<p>That said, the distinction between CI and AI is not so hard and fast, and arguably arose during the `AI Winter' when the term AI was out of fashion.</p>\n",
        "<p>Hidden layers by themselves aren't useful. If you had hidden layers that were linear, the end result would still be a linear function of the inputs, and so you could collapse an arbitrary number of linear layers down to a single layer.</p>\n\n<p>This is why we use nonlinear <a href=\"https://en.wikipedia.org/wiki/Activation_function\" rel=\"nofollow\">activation functions</a>, like RELU. This allows us to add a level of nonlinear complexity with each hidden layer, and with arbitrarily many hidden layers we can construct arbitrarily complicated nonlinear functions.</p>\n\n<p>Because we can (at least in theory) capture any degree of complexity, we think of neural networks as \"universal learners,\" in that a large enough network could mimic any function.</p>\n",
        "<p>Machine learning is a subset of artificial intelligence. Roughly speaking, it corresponds to its learning side. There is no \"official\" definitions, boundaries are a bit fuzzy.</p>\n",
        "<p>How would you estimate the generalization error? What are the methods of achieving this?</p>\n",
        "<p>\"Hidden\" layers really aren't all that special... a hidden layer is really no more than any layer that isn't input or output. So even a very simple 3 layer NN has 1 hidden layer. So I think the question isn't really \"How do hidden layers help?\" as much as \"Why are deeper networks better?\".  </p>\n\n<p>And the answer to that latter question is an area of active research. Even top experts like Geoffrey Hinton and Andrew Ng will freely admit that we don't really understand why deep neural networks work. That is, we don't understand them in complete detail anyway.</p>\n\n<p>That said, the theory, as I understand it goes something like this...  successive layers of the network learn successively more sophisticated features, which build on the features from preceding layers. So, for example, an NN used for facial recognition might work like this: the first layer detects edges and nothing else. The next layer up recognizes geometric shapes (boxes, circles, etc.). The next layer up recognizes primitive features of a face, like eyes, noses, jaw, etc. The next layer up then recognizes composites based on combinations of \"eye\" features, \"nose\" features, and so on.  </p>\n\n<p>So, in theory, deeper networks (more hidden layers) are better in that they develop a more granular/detailed representation of a \"thing\" being recognized.  </p>\n",
        "<p>I've implemented <a href=\"https://en.wikipedia.org/wiki/Reinforcement_learning\" rel=\"nofollow noreferrer\">the reinforcement learning algorithm</a> for an agent to play <a href=\"https://github.com/admonkey/snappybird\" rel=\"nofollow noreferrer\">snappy bird</a> (a shameless cheap ripoff of flappy bird) utilizing a q-table for storing the history for future lookups. It works and eventually achieves perfect convergence after enough training.</p>\n\n<p>Is it possible to implement a neural network to do function approximation in order to accomplish the purpose of the q-table? Obviously, storage is a concern with the q-table, but it doesn't seem to ever train with the neural net alone. Perhaps training the NN on an existing q-table would work, but I would like to not use a q-table at all if possible.</p>\n",
        "<p><strong>Machine learning</strong> has been defined by many people in multiple (often similar) ways [<a href=\"http://noiselab.ucsd.edu/ECE228/Murphy_Machine_Learning.pdf\" rel=\"noreferrer\">1</a>, <a href=\"http://www.cs.ubbcluj.ro/%7Egabis/ml/ML-books/McGrawHill%20-%20Machine%20Learning%20-Tom%20Mitchell.pdf\" rel=\"noreferrer\">2</a>]. One definition says that machine learning (ML) is the field of study that gives computers the <em>ability to learn</em> without being explicitly programmed.</p>\n<p>Given the above definition, we might say that machine learning is geared towards problems for which we have (lots of) data (experience), from which a program can learn and can get better at a task.</p>\n<p><strong>Artificial intelligence</strong> has many more aspects, where machines may not get better at tasks by learning from data, but may exhibit <em>intelligence</em> through rules (e.g. expert systems like <a href=\"https://en.wikipedia.org/wiki/Mycin\" rel=\"noreferrer\">Mycin</a>), <a href=\"https://silp.iiita.ac.in/wp-content/uploads/PROLOG.pdf\" rel=\"noreferrer\">logic</a> or algorithms, e.g. path-finding).</p>\n<p>The book <a href=\"http://aima.cs.berkeley.edu/\" rel=\"noreferrer\"><em>Artificial Intelligence: A Modern Approach</em></a> shows more research fields of AI, like <em>Constraint Satisfaction Problems</em>, <em>Probabilistic Reasoning</em> or <em>Philosophical Foundations</em>.</p>\n",
        "<p>I read that in the spring of 2016 a computer <a href=\"https://en.wikipedia.org/wiki/Computer_Go\" rel=\"nofollow noreferrer\">Go program</a> was finally able to beat a professional human for the first time.  </p>\n\n<p>Now that this milestone has been reached, does that represent a significant advance in artificial intelligence techniques or was it just a matter of even more processing power being applied to the problem?  </p>\n\n<p>What are some of the methods used to program the successful Go-playing program? </p>\n\n<p>Are those methods considered to be artificial intelligence?</p>\n",
        "<p>Many terms have 'mostly' the same meanings, and so the differences are just in emphasis, perspective, or historical descent. People disagree as to which label refers to the superset or the subset; there are people who will call AI a branch of ML and people who will call ML a branch of AI.</p>\n<p>I typically hear Machine Learning used as a form of 'applied statistics' where we specify a learning problem in enough detail that we can just feed training data into it and get a useful model out the other side.</p>\n<p>I typically hear Artificial Intelligence as a catch-all term to refer to any sort of intelligence embedded in the environment or in code. This is a very expansive definition, and others use narrower ones (such as focusing on artificial <em>general</em> intelligence, which is not domain-specific). (Taken to an extreme, my version includes thermostats.)</p>\n"
    ],
    "3dprinting": [
        "<p>When I've printed an object I've had to choose between high resolution and quick prints.  What techniques or technologies can I use or deploy to speed up my high resolution prints?</p>\n",
        "<p>I would like to buy a 3D printer, but I'm concerned about the health risks that are associated with its operation. Some groups of scientists say it can be <a href=\"http://www.techworld.com/news/personal-tech/scientists-warn-of-3d-printing-health-effects-as-tech-hits-high-street-3460992/\">harmful</a> for humans.</p>\n\n<p>What do I need to consider before buying a 3D printer if I care about my health? Are there any safe printers?</p>\n",
        "<p>I know the minimum layer height will effect how detailed of an item you can print and the amount of time it takes to print something, but is it necessary to have an extremely low minimum layer height if you plan to print only larger objects?</p>\n",
        "<p>Plastic is used in 3D FDM/FFF printing partly because it had a wide temperature range for its glass state - where it can be flowed with some force, but won't flow due only to gravity.</p>\n\n<p>Most metals have a very narrow, or non-existant, glass state.  They transition from solid to liquid with almost no flowable-but-not-liquid state.</p>\n\n<p>Are there any metals or alloys that display a glass transition state?</p>\n",
        "<p>What are the main differences when using ABS over PLA and vice versa?</p>\n",
        "<p>My MakerBot printer supports only two filaments at the same time.</p>\n\n<p>What are techniques to print objects with more than two colors for one object?</p>\n",
        "<p>Filament is the plastic strands used as the print material for 3d printers. The most common types are PLA and ABS. There are also other types of filament that used other types of plastics as well as other materials.</p>\n",
        "For questions related to different filaments used as the print material.",
        "<p>Almost all 3D printers have issues that could cause health problems.</p>\n\n<p>FDM/FFF printers heat plastic to a temperature that may cause it to off-gas, and these byproducts may not be healthy.</p>\n\n<p>SLA printers often use epoxies that may off-gas, or may be somewhat toxic prior to being cured.</p>\n\n<p>Powder based printers can also off-gas, in addition to the powder itself presenting a possible hazard.</p>\n\n<p>Many hobbyist and small companies dance around the problem, and suggest that the machines always be used in well ventillated areas.  Professional machines often have filters and ventillation systems built in.</p>\n\n<p>Rather than trying to find a \"perfectly safe\" 3D printer, spend some time deciding what you want to use one for, find printers suitable for your use, and expect that you'll need to provide reasonable ventilation for almost any printer.  Plan your installation for that, and you should be able to make any printer safe for your required use.</p>\n\n<p>If, however, you plan on setting up a printer farm with many printers, and plan to have yourself or others spend significant time operating them, I suggest you work with a health and safety professional and have them identify possible hazards and plan mitigation.</p>\n",
        "<p>I'd like to print modifications for my bird feeder, both to patch over the hail damage from last summer and to try to deter the neighborhood squirrels.  I have an FDM printer (and experience with nylon, ABS, and PLA, though don't restrict answers to those if there's something else that's better), what kind of filament would stand up best to daily exposure to sun, rain, snow, etc?</p>\n",
        "<p>The surfaces of my printed parts using PLA plastic look rough and uneven.</p>\n\n<p>Would changing filament to a better one make any difference?</p>\n\n<p>If not, what kind of methods can I use to achieve a smoother finish for my for 3D-printed objects?</p>\n",
        "<p>There is very little information about safety available, as home 3D printers are relatively new. However, plastics such as ABS have a long history in making plastic products, and a study found that at traditional manufacturing methods (such as injection molding and hot wire cutting) <a href=\"http://annhyg.oxfordjournals.org/content/57/3/399\">do not release dangerous levels of carcinogens and/or respiratory sensitizers in to the air</a>.</p>\n\n<p>Of course, 3D printers are not among the processes covered in the study. In home 3D printing circles, <a href=\"http://www.sciencedirect.com/science/article/pii/S1352231013005086\">this study</a> that looks at ultrafine particle (UFP) emissions, is often cited. It finds that printing ABS releases relatively high levels of UFP's and PLA releases significantly fewer (but still quite a large amount). However, it is unclear whether/how dangerous these UFP's are in the amounts emitted.</p>\n\n<p>It is often suggested that PLA, partly because of the reduced UFP emissions is safer to print than ABS, partly because of its \"natural\" origins as it can be derived from materials such as cornstarch. I would caution against this line of reasoning since \"natural\" materials can still be poisonous (snake venom is natural, after all) and the cornstarch is heavily processed so it hardly resembles its original form. The lower UFP emissions may suggest it is safer, but the study is only quantitative, not qualitative.</p>\n\n<p>That said, PLA does probably pose less of a risk (despite my earlier argumentation against \"natural\" materials, PLA does play quite nicely with the human body), but I contend the risk with ABS is not too large anyways, given that it has been safely used in factories for decades.</p>\n\n<p><a href=\"http://fire.nist.gov/bfrlpubs/fire86/art017.html\">Another study</a> is often miscited, supposedly saying that 3D printing ABS releases hydrogen cyanide. The study only looks at the thermal decomposition of ABS, which happens at significantly higher temperatures than are reached during printing (but a significantly malfunctioning printer might cause toxic gasses to be released, but I contend that at that point you should worry about your printer being on fire, rather than temporary exposure to some toxins).</p>\n\n<p>There are no printers out there that are fundamentally safer than others. However, some printers have an enclosure (containing the fumes) and some even have a carbon filter and a fan for fume extraction. If you would like to err on the side of caution, this might be a good choice (but again, it is not clear if a carbon filter is totally effective).</p>\n\n<p>Finally, as printers are generally quite noisy it tends to be preferrable to keep your printer in a separate room from where you usually work. In this case, fume exposure (during the few minutes that you go to check on your print) is minimal, and the potential advantages of a \"safer\" printers or using \"safer\" materials diminish.</p>\n\n<p>Incidental exposure as a hobbyist is probably not a big deal; workers in factories are exposed to the fumes of melted plastic their entire lives and they don't seem to be dropping dead. On the other hand, if you are going to be printing structurally then it is probably preferable to move your printer to a separate room, if not because of health and safety because of the noise.</p>\n",
        "<p>With an ABS or PLA extrusion 3D printer, are there any potentially negative quality differences that could occur if I try to print at a higher resolution?</p>\n\n<p>I am not concerned about print time as the equipment is not under high demand.  I am, however, worried the device may be more prone to fracture, likely to have defects, or have other issues I cannot currently imagine.</p>\n",
        "<p>I would like to print parts (e.g. jewellery) for use which I don't want to look or feel like a plastic, but metal-like, so briefly people won't see much difference.</p>\n\n<p>Are there any specific type of home-printers that can achieve that? Or it's rather kind of filament that you should use?</p>\n",
        "<p>Apart from the inherent process itself and direct health hazards from that, many 3D printers also require some complementary technology to work.</p>\n\n<p><a href=\"/questions/tagged/fdm\" class=\"post-tag\" title=\"show questions tagged &#39;fdm&#39;\" rel=\"tag\">fdm</a> printers have a printing head that needs to move around in 3D space. <strong>Moving machinery parts can be a hazard</strong>. In a home/hobbyist environment with children for example, I would recommend to buy a printer with a housing. </p>\n\n<p>\"open\" designs often feature <strong>bare electronics</strong> mounted directly to the printer structure. This rises the possibility of short circuits and electric shock.</p>\n\n<p>The printers that heat material often do so at very high temperatures. <strong>Hot parts of the printer</strong> should not be touched.</p>\n",
        "<p>I am aware of several \"clear\" filaments for a ABS or PLA printer.  They, however, have a cloudy or frosted glass appearance. I do not believe this is possible to eliminate but I believe it can be reduced.</p>\n\n<p>Are there effective ways to make a print have a more transparent appearance?</p>\n",
        "<p>I\"m no expert on this, but the article at <a href=\"https://en.wikipedia.org/wiki/Amorphous_metal\" rel=\"noreferrer\">https://en.wikipedia.org/wiki/Amorphous_metal</a> may be relevant for you.</p>\n\n<p>There are some special alloys, such as gold/silicon and various titanium-based ones, that become \"bulk metal glasses\" if cooled extremely quickly (for example, by sputtering onto a spinning cold surface). The speed of cooling prevents crystal formation. Early BMGs were quite strong but brittle; improvements have reduced brittleness and required cooling speed.</p>\n",
        "<p>PET(G) is a strong contender. It is very strong and water-resistant, and as such is often used to make pop bottles.</p>\n\n<p>PLA has a reputation for being \"biodegradable\" and therefore it is often discouraged to use PLA outside and/or in contact with water. However, PLA only biodegrades under very specific conditions which it won't generally be exposed to so it can be used (though, as a harder and less flexible material it is more likely to be damaged by hail).</p>\n\n<p>ABS and Nylon are good choices as well. Basically, any plastic you have on hand will last for years, even in an outside application.</p>\n",
        "<p>My printed parts consist rafts, supports and other extraneous filament when printing with ABS or PLA.</p>\n\n<p>What are efficient general techniques of removing them?</p>\n",
        "<p>I would like to understand the differences between rafts, skirts and brims. They appear in the software which I'm using to edit my 3D objects.</p>\n\n<p>Can anybody elaborate what are these and what are the main differences between them?</p>\n",
        "<p>It is called <strong>Acetone Finishing</strong></p>\n\n<p>Basically the 3D printed part stays in acetone vapor and the outer shell turns to smooth surface. I have heard that it works better with ABS. </p>\n\n<p>This article shows how <em>with videos</em>:</p>\n\n<ul>\n<li>(<a href=\"https://ultimaker.com/en/community/10412-acetone-finishing-on-pla\" rel=\"nofollow noreferrer\">Acetone Finishing on PLA</a> - dead link). </li>\n<li>New link: <a href=\"https://community.ultimaker.com/topic/8530-acetone-finishing-on-pla/\" rel=\"nofollow noreferrer\">Acetone Finishing on PLA</a> </li>\n</ul>\n",
        "<p>I've acquired all the parts to build a Reprap Prusa i3 rework, the only missing part is the frame. </p>\n\n<p>I'm in doubt between a MDF cut (cheaper) or acrylic (more expensive), of course a cheaper one is my preferred option until I see any disadvantage on making it of wood. </p>\n\n<p>I thought about variables like heat and humidity and the possibility of expansion/contraction of the frame, is this a valid concern? Will I have more precision buying the acrylic one or is it irrelevant?</p>\n",
        "<p>Use Taulman t-glase and after a light sanding with really fine paper (optional really, but go for it if you can), spray it with polyurethane varnish or something similar. Check out the article <a href=\"http://3dprint.com/29292/taulman-hacks-clear-t-glase-3d-printing-material/\">here</a>.</p>\n",
        "",
        "It is the 3D Printer design by RepRap Core Developer Prusajr",
        "<p>Generally speaking, MDF will weather OK. In areas of high humidity you might experience warpage, but you can mitigate that by sealing the surface with paint or varnish.  However you will probably find that of the two materials, acrylic will be more stable over a few years.</p>\n",
        "<p>The most obvious solution is to pause the print and swap filament for another color.</p>\n\n<p>Another option is to <a href=\"https://www.youtube.com/watch?v=RdlqGR5n9Zk\">splice pieces of filament</a> together, though this does not allow very precise control of when the switch happens. There is also a device that can automatically slice filament this way.</p>\n\n<p>Finally, another option that uses very little external equipment is to <a href=\"http://reprap.org/wiki/Coloring_filament\">use (permanent) markers to colorize light-colored filament</a>.</p>\n\n<p>Other options include upgrading to a printer with more hotends, or installing a hotend with multiple filament inputs and one outputs, but these options would involve significantly changing your printer setup.</p>\n",
        "<p>I've seen article about <a href=\"http://www.pinkbike.com/news/Worlds-first-3D-printed-bike-2014.html\" rel=\"nofollow\">World's First 3D Printed Bike</a>.</p>\n\n<p>What kind of printer is required to do that, briefly how long it takes and how much does it cost? Is this even achievable at home? Doesn't need to be that specific one. </p>\n",
        "<p>You can make a mold from the print and then get a cast from that mold with a clear casting material.</p>\n",
        "<p>Your two easiest options are dipping your print in acetone or giving it an acetone vapor bath. Note this process generally only works with <strong>ABS</strong> not <strong>PLA</strong>, with the exception of some brands. There are <a href=\"http://fabsterdam.com/3dprinting/smoothing-pla/\" rel=\"noreferrer\">many</a> <a href=\"http://fabsterdam.com/3dprinting/smooooooth/\" rel=\"noreferrer\">articles</a> <a href=\"https://ultimaker.com/en/community/10412-acetone-finishing-on-pla\" rel=\"noreferrer\">online</a> where you can learn more about the process.</p>\n\n<p>Aside from finishing, you will generally get a smoother looking end result by <strong>lowering the layer thickness</strong>, and <strong>removing any hysteresis/wobble</strong> in your print head making sure it's well calibrated.</p>\n",
        "<p>You will need a laser sintering or lasercusing printer, which will not be something you can buy for home use. They are horribly expensive.</p>\n\n<p>You could always print this in PLA or ABS and cast it in aluminium. Then you have to find a safe method to test the result, because casting is not quite as simple as it looks and the bike could be seriously dangerous.</p>\n",
        "<p>There is a 3D desktop printer <a href=\"https://en.wikipedia.org/wiki/RepRap_project\">RepRap</a> which can print most of its own components.</p>\n\n<p>Assuming each printed printer will print the next one and so on. Are there any limitation how many times this can be achieved?</p>\n\n<p>For example somebody printed for me printer and I do the same for my friends and they do the same for theirs. Can this go forever (since 3D model stays the same), or there are any serious side-effects/disadvantages of doing that continuously?</p>\n",
        "<p><a href=\"https://en.wikipedia.org/wiki/Polylactic_acid\">PLA</a> parts can be finished with a coat of epoxy like <a href=\"http://www.smooth-on.com/Epoxy-Coatings-XTC/c1397_1429/index.html\">XTC-3D from Smooth-On</a>. This will smooth out the part and give it a pretty nice shine.</p>\n\n<p>I've also had a fair amount of success sanding prints, giving them a coat of automotive filler primer, and using glossy spray paint.</p>\n\n<p>You can also get great results with an acetone <a href=\"https://en.wikipedia.org/wiki/Vapor_polishing\">vapor finish</a> if you're willing to switch to <a href=\"https://en.wikipedia.org/wiki/Acrylonitrile_butadiene_styrene\">ABS</a>. Though that will require a heated bed and can be a bit more finicky to work with than PLA.</p>\n",
        "<p>On a number of occasions I've broken small plastic parts that are nearly impossible to replace but could easily be 3-D printed.  The latest such mishap is the volume knob on the factory-installed radio on my car.  </p>\n\n<p>I have little experience in 3D printing, and would like to be able to replace these parts with something very close to the original.  Spending hours measuring and designing a replacement part that should be $5 isn't really an option.  I need something to scan the broken pieces in 3D and somehow just seal up the seam where it's broken.</p>\n\n<p>Is there a scanning/printing/software system to do this that doesn't require a lot of 3D design experience?</p>\n",
        "<p>Acetone vaporing is a great way to smooth ABS prints. For PLA, however, acetone smoothing does not work. An <a href=\"http://fabsterdam.com/3dprinting/smoothing-pla/\" rel=\"noreferrer\">article about smoothing PLA</a> says:</p>\n\n<blockquote>\n  <p>This is a pity, since PLA is much easier to work with than ABS. We found some solutions for smoothing PLA, but most involve rather dangerous-sounding chemicals such as <a href=\"http://www.protoparadigm.com/news-updates/vapor-smoothing-and-polishing-pla-with-tetrahydrofuran-thf/\" rel=\"noreferrer\">Tetrahydrofuran</a> and <a href=\"http://www.thingiverse.com/thing:74093\" rel=\"noreferrer\">Dichloromethane</a>. The one exception we found is <a href=\"http://www.printedsolid.com/smoothpla/\" rel=\"noreferrer\">Ethyl Acetate</a> which seems to give good results and is (relatively) safe.</p>\n</blockquote>\n\n<p>Other article mentioned <a href=\"http://printedsolid.com/blogs/news/37035395-vapor-smoothing-3d-printed-parts-pla-colorfabb-xt-t-glase-pet\" rel=\"noreferrer\">MEK Substitute</a>, which is Ethyl Acetate as well. You could also try some kind of polisher manufactured for 3D print results, such as <a href=\"http://www.smooth-on.com/Epoxy-Coatings-XTC/c1397_1429/index.html\" rel=\"noreferrer\">XTC-3D</a>. Here is a real photo of XTC-3D on PLA:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Auq4H.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/Auq4H.jpg\" alt=\"XTC-3D on PLA, image courtesy of tiskni3ddoma.cz\"></a></p>\n\n<p>Ultimaker also <a href=\"https://ultimaker.com/en/tips-tricks/17897-vapor-treating\" rel=\"noreferrer\">suggests using chloroform</a> for smoothing PLA prints.</p>\n\n<p>If your parts are really uneven, it might be a symptom of something bad going on with your print(er), you might want to read <a href=\"https://www.evernote.com/shard/s211/sh/701c36c4-ddd5-4669-a482-953d8924c71d/1ef992988295487c98c268dcdd2d687e\" rel=\"noreferrer\">Taxonomy of Z axis artifacts in extrusion-based 3d printing</a>.</p>\n\n<blockquote>\n  <p>The most recognizeable cause of this problem is Z-wobble. It is caused by the misalignment of layers in a repeating pattern with a period equal to the Z thread pitch (technically the lead, but this is the same as the pitch unless you are using a multi-start thread), and was a famous problem of the original Makebot, the CupcakeCNC.</p>\n</blockquote>\n",
        "<p>As long as you maintain each printer and keep a proper calibration, go for it, this is what they were designed to do, I've even made replacement parts for myself.</p>\n<p>Unfortunately the <a href=\"https://en.wikipedia.org/wiki/RepRap_project#History\" rel=\"nofollow noreferrer\">RepRap project just shut down on January 15th 2016</a> due to their lack of sales.</p>\n<p>I have a reprap that came from a reprap, and has made another reprap.</p>\n<p>Just make sure that when printing out the pieces for the next you are properly calibrated, otherwise the next machine might be built crooked;</p>\n<p>Your only limitations will be the electronics pieces and the small amount of hardware that you will need to buy.</p>\n",
        "<p>I have a few kg of 3&nbsp;mm filament when I only have use for 1.75&nbsp;mm.</p>\n\n<p>How can I make 1.75&nbsp;mm from 3&nbsp;mm filament?</p>\n",
        "<p>The files used to print these objects are digital, and do not degrade in any way after each printing. There are no side effects or degradation that occurs over time due simply to printing them multiple times.</p>\n\n<p>This is the RepRap philosophy, and the machines are actually designed with enough tolerance for printing and building mistakes that even if the print isn't perfect, it will not only work fine, but it can print a printer better than it was printed, with some care and attention to calibration.</p>\n\n<p>The process still takes a lot of human intervention, in the way of building the new printer and properly calibrating it.  If there are errors in the printer or the prints it produces, they can almost always be attributed to the builder/calibrator/user, and not to the design or the fact it's the Nth generation of printer.</p>\n",
        "<p>I would like to print 3D desktop printer, but currently I know only <a href=\"https://en.wikipedia.org/wiki/RepRap_project\" rel=\"nofollow\">RepRap</a> project. Ideally I'm looking for some better quality or larger alternatives (e.g. for printing larger parts than RepRap allows).</p>\n\n<p>Are there any?</p>\n",
        "<p>The easiest way is as you currently do: model the pieces by hand, using (digital) calipers to measure them.</p>\n\n<p>Scanning technology isn't very good, and the models are not of printable quality. Usually, fixing a scan is more work than modeling an item from scratch.</p>\n",
        "<p>The best option is to find somebody in need of 3&nbsp;mm filament and trade them for it (either in exchange for 1.75&nbsp;mm filament or in exchange for legal tender with which to buy said filament).</p>\n\n<p>The next best option would be to cut it into small pieces, and feed those into a filament extrusion system such as the <a href=\"http://www.filastruder.com/\" rel=\"nofollow noreferrer\">filastruder</a>.</p>\n",
        "<p>In theory, making filament is easy.  You take a 3&nbsp;mm hotend with a 1.75&nbsp;mm hole, and extrude the 3&nbsp;mm (sometimes actually 2.85&nbsp;mm) filament, let it cool, and then reel it up.</p>\n\n<p>In reality there are a lot of pitfalls to making filament - if the pressure isn't even, the hole not perfect, the temperature uneven, you can end up with oval filament, filament with bubbles, or worse.  If you are over temperature you may damage the filament and it could look good, but not melt correctly when used.  If you reel it too fast you may thin it out more than the intended diameter, or too slow and you may thicken it. A lot of hotends use steppers, which may result in ripples in the filament, so you may end up building a nearly custom filament machine.</p>\n\n<p>Resolving all these problems is probably not worth simply selling or giving away the filament to someone that can use it, and buying the right size for your machine.</p>\n\n<p>If you are still interested, though, you might as well go all the way and build a full filament extruder that accepts raw plastic feedstock (usually pellets) as well as your filament, and convert it that way, then continue using it to create your own filament.</p>\n",
        "<p>You could build a machine that has a nozzle with 3 mm input hole and 1.75 mm output hole, based on some designs for filament making machines. Or you could just cut the filament into little peaces and use them instead of the granulate in an original filament making machines.</p>\n\n<p>There are some open designs for such machines <a href=\"http://www.instructables.com/id/Build-your-own-3d-printing-filament-factory-Filame/\" rel=\"nofollow noreferrer\">you can build</a>, or you could buy one, such as <a href=\"http://www.filabot.com/collections/filabot-core\" rel=\"nofollow noreferrer\">Filabot</a>.</p>\n\n<p>However, as mentioned by <a href=\"https://3dprinting.stackexchange.com/users/36/kaine\">kaine</a>, this is very unlikely to be worth the cost/effort. Best option for you is to try to sell the 3 mm filament to someone who has a use for it, take the money and buy some 1.75 mm filament instead.</p>\n",
        "<p>The reprap printers have often been compared to plants, providing fruits to you and the possibility to reproduce themselves.</p>\n\n<p>This analogy holds in both good and bad ways. Any life form can reproduce itself only so often without artefacts (mutations) being introduced.</p>\n\n<p>It takes a bit of <strong>skill to build, configure and run a reprap printer</strong>. While the parts can be passed on, that doesn't necessarily hold for gained experience.\nChances are that the parts your printer produces are not as good as those that you have received to build the printer. At least not until you caught up on the learning curve.</p>\n\n<p>A reprap has a lot <strong>other parts that are not printed and can vary in quality independently from the printed parts</strong>. It makes a difference what steel rods are used, what driver circuit for the motors, etc. If you give printed parts away that are as good as those that you received yourself, the added parts are not necessarily as good as your.</p>\n\n<hr>\n\n<p>My recommendation would be that <strong>you and your friends get printer parts from that somebody and you build your printers together</strong>. While giving parts to others is a great thing, building 3D printers together with friends is greater. </p>\n",
        "<p>If you'd like to print on RepRap like <a href=\"https://en.wikipedia.org/wiki/Fused_deposition_modeling\" rel=\"nofollow noreferrer\">FDM printers</a>, you cannot print from metal, but you can use some filament that tries to look like metal. I have good experience with <a href=\"http://colorfabb.com/bronzefill\" rel=\"nofollow noreferrer\">Bronzefill</a>, but there are plenty of others, just Google for <em>metal filament 3d printing</em>. Note that sometimes the parts need to be post-processed with a <em>rock tumbler</em>. There are <a href=\"https://www.thingiverse.com/tag:rock_tumbler\" rel=\"nofollow noreferrer\">several open source DIY tumblers</a> you can build and use.</p>\n\n<p>If you actually want to print from metal, you would need SLS (<a href=\"https://en.wikipedia.org/wiki/Selective_laser_sintering\" rel=\"nofollow noreferrer\">Selective laser sintering</a>) printer, which is much more expensive.</p>\n",
        "<p>I am printing a print using PLA on a Prusa i3 printer and an MK8 extruder, at 210 degrees celsius, 60 mm/sec, sliced with slic3r. The print consists of a base, with 4 tower-like projections that then join with a near-vertical overhang slope that isn't posing a problem for my printer.</p>\n\n<p>However, even before the overhang begins, I am getting large amounts of strings as the extruder head jumps between the four towers in the print, leading to a \"spiderweb\" effect between them. How can I deal with these strings, and are they a warning that there might be something amiss with my printer, or possible other failures in other parts of the print?</p>\n",
        "<p>When using thermoplastic-filament, this can be potentially <a href=\"https://3dprinting.stackexchange.com/q/2/20\">hazardous</a>, since constant printing can emit hazardous fumes and odors that may be emitted by heating the plastics.</p>\n\n<p>I understand it normally should be used in well ventilated areas. However I would like to use it heavily in the basement which is not well ventilated.</p>\n\n<p>Are there any practical methods of limiting such exposure? For example locking it in some special box, covering it or suck the odors? Would that help?</p>\n\n<p>Do you have any experience doing so?</p>\n",
        "<p>You could experiment with slicing. For example, you might not need high resolution all over the object, but you can speed up some straight parts by using greater layer high there. See a <a href=\"http://manual.slic3r.org/expert-mode/variable-layer-height\">part of Slic3r manual</a> about such thing.</p>\n\n<p>It is also possible to print thicker infill every Nth layer, see <a href=\"http://manual.slic3r.org/expert-mode/infill-optimization\">Infill optimization</a> in Slic3r.</p>\n\n<p>Other slicers might have those features as well.</p>\n",
        "<p>Stringing is often a result of too-high a temperature, or insufficient retraction. When there is highly liquid filament in the nozzle tip, it can adhere to the remainder of the print while dripping as the nozzle moves, leading to a thin string of the filament forming. As further travel moves are performed in each layer, this turns to a web.</p>\n\n<p>The high temperature causes filament to be very liquid, causing it to move downward in the nozzle chamber easily, as opposed to having to be extruded forcefully due to viscosity. The temperature setpoint of 210 was high enough to cause this to happen.</p>\n\n<p>A second possible cause, insufficient retraction, can also be blamed for this issue. Retraction is a process in which the extruder reverses its movement to pull filament back up the hotend, preventing it from dripping at the tip, and forming a string. Most slicers will allow specifying a numeric value in millimeters of filament to be retracted. Remember that printers with Bowden tubes between nozzle/hotend and extruder motor will require increased retraction and priming (extrusion when starting to print after a retract-and-move). Note that too much retraction can cause other problems, such as insufficient plastic in the hotend chamber at the start of the next printing move, which can cause gaps and other issues.</p>\n",
        "<blockquote>\n  <p>parts ... I don't want to ... feel like a plastic</p>\n</blockquote>\n\n<p>This is harder than looking like metal.  Plastic doesn't have nearly the density of metal, nor the thermal conductivity of metal.  So by touch people will be able to tell the difference between almost any metal item, and a plastic item that looks similar.</p>\n\n<p>For jewelry, as long as the wearer doesn't mind that it's not metal (they will be able to tell) you can fool most viewers with proper finishing.  Sanding/smoothing, and then painting the printed part will work for most things.</p>\n\n<p>For things which dangle significantly, the swinging and action of the item may give away its density, but some objects people expect to be hollow metal can be printed in solid or high density plastic and give the same weight, though they are lower density. </p>\n\n<blockquote>\n  <p>Are there any specific type of home-printers that can achieve that?</p>\n</blockquote>\n\n<p>For things which feel metallic, no, except for very small items where the weight and thermal conductivity won't be significant.  A laser sintering printer could make real metal parts if this is needed, but these don't fall into the category of home machines.</p>\n\n<p>If you don't mind a multi step process, you can make molds of the printed object, then cast real metal, or very high density epoxies, to accomplish your goal.</p>\n\n<p>Beyond that, a high resolution machine with a lot of hand-finishing work is going to get you as close as you'll get to looking like metal.</p>\n",
        "<p>I want to print a model of an animal cell.</p>\n\n<p>What I have so far: I managed to use different colors to print out the different parts of the cell.<br>\nMy question is: what is the best way to connect plastic 3d printed parts?<br>\nGlue? Melted plastic? I need it to have a strong connection and not very visible when used well, and preferable dries fast.</p>\n"
    ],
    "bioinformatics": [
        "<p>I'd like to learn which format is most commonly used for storing the full human genome sequence (4 letters without a quality score) and why.</p>\n\n<p>I assume that storing it in plain-text format would be very inefficient. I expect a binary format would be more appropriate (e.g. 2 bits per nucleotide).</p>\n\n<p>Which format is most common in terms of space efficiency?</p>\n",
        "<p>In terms of raw storage capacity 2 bits per nucleotide, and then further compressed with standard compression techniques would be the most efficient. However, you'd still have other storage considerations. Like what to do about non-standard bases: like if you want to indicate a gap or ambiguity. </p>\n\n<p>I'd also query if it is really necessary to store them as binary since it reduces the readability of the data. It is quite convenient having a whole bunch of unix and programming tools that can operate on the string level in text files.</p>\n",
        "<p>Genomes are commonly stored as either fasta files (.fa) or twoBit (.2bit) files. Fasta files store the entire sequence as text and are thus not particularly compressed. </p>\n\n<p>twoBit files store each nucleotide in two bits and contain additional metadata that indicates where there's regions containing <code>N</code> (unknown) bases.</p>\n\n<p>For more information, see the documentation on the twoBit format at the <a href=\"http://genome.ucsc.edu/FAQ/FAQformat.html#format7\" rel=\"noreferrer\">UCSC genome browser</a>.</p>\n\n<p>You can convert between twoBit and fasta format using the <a href=\"https://genome.ucsc.edu/goldenpath/help/twoBit.html\" rel=\"noreferrer\">faToTwoBit and twoBitToFa utilities</a>.</p>\n\n<p>For the human genome, you can download it in either fasta or twoBit format here: <a href=\"http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/\" rel=\"noreferrer\">http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/</a></p>\n",
        "<p>The standard formats for storing sequence data are <a href=\"https://en.wikipedia.org/wiki/FASTA_format\" rel=\"noreferrer\">fasta</a> and <a href=\"https://en.wikipedia.org/wiki/FASTQ_format\" rel=\"noreferrer\">fastq</a>.  Fasta is used if you only need the raw sequence data, fastq is used if you want to store the sequence data along with the quality information from base calling.  Each of these can be compressed using gzip or another standard compression algorithm.</p>\n\n<p>Typically we want to keep the quality information along with the raw sequence data, but the quality information accounts for half the storage space required.  Some people have developed <a href=\"https://web.stanford.edu/~mainakch/papers/QualComp_Final_v2.pdf\" rel=\"noreferrer\">algorithms</a> for lossy compression of the quality data that allow us to reduce the storage requirements.</p>\n\n<p>If you are interested in storing variant calling data, the standard format for that is <a href=\"http://www.internationalgenome.org/wiki/Analysis/vcf4.0/\" rel=\"noreferrer\">VCF</a>.  VCF is useful if you want to store quality information of the variant calls, genomic positions, and any annotations you might have about the position.  VCFs can be compressed and indexed using <a href=\"http://www.htslib.org/doc/tabix.html\" rel=\"noreferrer\">bgzip and tabix</a>.  Many tools require variant data to be compressed and indexed using these tools.</p>\n",
        "<p><a href=\"https://en.wikipedia.org/wiki/Human_Genome_Project\" rel=\"noreferrer\">The Human Genome Project</a> was the project of 'determining the sequence of nucleotide base pairs that make up human DNA, and of identifying and mapping all of the genes of the human genome'. It was declared complete in 2003, i.e. 99% of the euchromatic human genome completed with 99.99% accuracy.</p>\n\n<p>Are the datasets provided by HGP still accurate, or as accurate as was claimed in 2003? </p>\n\n<p>Given the technology in the past (such as using old techniques), or any other reason (newer research studies), is it possible that the datasets are not as accurate as originally expected?</p>\n",
        "",
        "The Human Genome Project was a scientific research project with the goal of determining the sequence of human DNA.",
        "<p>I'm interested working with the medication information provided by the <a href=\"http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=20003\" rel=\"noreferrer\">UK Biobank</a>.  In order to get these into a usable form I would like to map them to <a href=\"https://en.wikipedia.org/wiki/Anatomical_Therapeutic_Chemical_Classification_System\" rel=\"noreferrer\">ATC codes</a>.  Since many of the drugs listed in the data showcase include dosage information, doing an exact string match between drug names is not very effective.  I've considered using something like <a href=\"https://pypi.python.org/pypi/fuzzywuzzy\" rel=\"noreferrer\">fuzzywuzzy</a> to do string matching between the medications in the data showcase and the ATC drug names but validating the matches could still be a laborious process.  Does anyone know of a tool that can match drug names to ATC codes or some other drug ontology?  If not, maybe there's a better way to do it that I haven't thought of.</p>\n",
        "<p>There are several things to consider when asking for \"the most efficient\" way to store data, it all depends on your use case. Do you just need ACGT, or are there also IUPAC codings for combinations? Do you need additional data (like quality values)? What kind of application are you using the data for (does it need to load all at once or in in chunks? Once or multiple times? Sequential or random access? etc.pp)?</p>\n\n<p>E.g., most efficient for:</p>\n\n<ol>\n<li>Lowest footprint on disk, without a lot of hassle: use either FASTA or 2bit, but run through standard compressor (gzip, bzip2, others). The literature you want to consult here is that of standard text compression I think. Also of interest <a href=\"http://mattmahoney.net/dc/text.html\" rel=\"noreferrer\">Large Text Compression Benchmark</a></li>\n<li>Keeping the file on disk, but ultra-fast loading small subsets into memory, being able to work in memory with character sized entities: a simple dump of the DNA as characters to disk, maybe combined with an index file to know which chromosome starts where. Then use <a href=\"http://pubs.opengroup.org/onlinepubs/009695399/functions/mmap.html\" rel=\"noreferrer\">mmap</a></li>\n<li>Storing quality values: See papers like <a href=\"http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0059190\" rel=\"noreferrer\">Compression of FASTQ and SAM Format Sequencing Data</a> or <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3637481/\" rel=\"noreferrer\">Sequence squeeze: an open contest for sequence compression</a></li>\n<li>Any combination of the above use cases + a lot more</li>\n</ol>\n",
        "<p>I'm looking to dock a large ligand (~90kDa) to a receptor slightly larger receptor  (~125kDa) using Hex. If anyone is familiar with docking large structures, are there any recommended parameters for finding the best docking solution?</p>\n\n<p>Parameters in particular:</p>\n\n<ul>\n<li>Number of Solutions  </li>\n<li>N order of correlation for initial and final\nsearches </li>\n<li>Receptor Range </li>\n<li>Ligand Range</li>\n</ul>\n",
        "<p>The HGP developed the first \"reference\" human genome - a genome that other genomes could be compared to, and was actually a composite of multiple human genome sequences. </p>\n\n<p>The standard human reference genome is actually continually updated with major and minor revisions, a bit like software. The <a href=\"https://www.ncbi.nlm.nih.gov/grc/human\" rel=\"noreferrer\">latest major version</a> is called GRCh38, was released in 2013, and has since had a number of minor updates. </p>\n\n<blockquote>\n  <p>Are the datasets provided by HGP still accurate?</p>\n</blockquote>\n\n<p>Yes, in a sense, but we certainly have better information now. One way to measure the quality of the assembly is that the initial release from the HGP <a href=\"https://www.nature.com/nmeth/journal/v7/n5/full/nmeth0510-331.html\" rel=\"noreferrer\">had hundreds of thousands</a> of gaps - sequences that could not be resolved (this often occurs because of repetitive sequences). The newest reference genome has less than 500 gaps.</p>\n",
        "<p>I'd like to learn the differences between 3 common formats such as <a href=\"https://en.wikipedia.org/wiki/FASTA_format\" rel=\"noreferrer\">FASTA</a>, <a href=\"https://en.wikipedia.org/wiki/FASTQ_format\" rel=\"noreferrer\">FASTQ</a> and <a href=\"https://en.wikipedia.org/wiki/SAM_(file_format)\" rel=\"noreferrer\">SAM</a>. How they are different? Are there any benefits of using one over another?</p>\n\n<p>Based on Wikipedia pages, I can't tell the differences between them.</p>\n",
        "<p>Many of my colleagues recommend I use BWA-MEM instead of regular old BWA. The problem is I don't understand why and reading the BWA man page doesn't seem to help the matter.</p>\n\n<p>What is the difference between BWA and BWA-MEM? And, in which instances would you employ one over the other?</p>\n",
        "<p>It is not yet standardized, but <a href=\"https://www.sevenbridges.com/graph/better-reference/\" rel=\"noreferrer\">graph format</a> has the potential for being the most space-efficient method for storing genomes.  The idea is this: rather than store a genome as a linear string of sequenced nucleotides, genomes are stored as overlapping graphs, where sequence variants branch off from the reference genome, and then rejoin when the alignment continues.  Basically, you start with a reference genome, and for every subsequent genome added to the graph, only the differences are stored.  This could allow for an enormous gain in space efficiency. </p>\n",
        "<p>FASTA (officially) just stores the name of a sequence and the sequence, unofficially people also add comment fields after the name of the sequence. FASTQ was invented to store both sequence and associated quality values (e.g. from sequencing instruments). SAM was invented to store alignments of (small) sequences (e.g. generated from sequencing) with associated quality values and some further data onto a larger sequences, called reference sequences, the latter being anything from a tiny virus sequence to ultra-large plant sequences.</p>\n",
        "<p>In a nutshell, </p>\n\n<p><code>FASTA</code> file format is a DNA sequence format for specifying or representing DNA sequences and was first described by Pearson <code>(Pearson,W.R. and Lipman,D.J. (1988) Improved tools for biological sequence comparison. Proc. Natl Acad. Sci. USA, 85, 2444\u20132448)</code> </p>\n\n<p><code>FASTQ</code> is another DNA sequence file format that extends the FASTA format with the ability to store the sequence quality. The quality scores are often represented in  ASCII characters which correspond to a phred score)</p>\n\n<p>Both FASTA and FASTQ are common sequence representation formats and have emerged as key data interchange formats for molecular biology and bioinformatics. </p>\n\n<p><code>SAM</code> is format for representing sequence alignment information from a read aligner. It represents sequence information in respect to a given reference sequence. The information is stored in a series of tab delimited ascii columns. The full SAM format specification is available at <a href=\"http://samtools.sourceforge.net/SAM1.pdf\" rel=\"noreferrer\">http://samtools.sourceforge.net/SAM1.pdf</a> </p>\n",
        "<p>A common bioinformatics task is to decompose a DNA sequence into its constituent k-mers and compute a hash value for each k-mer. <a href=\"https://en.wikipedia.org/wiki/Rolling_hash\" rel=\"noreferrer\">Rolling hash functions</a> are an appealing solution for this task, since they can be computed very quickly. A rolling hash does not compute each the hash value from scratch with each k-mer: rather it updates a running hash value using an update strategy and a sliding window over the data.</p>\n\n<p>It's also very useful for many applications to have a k-mer hash to the same value as its reverse complement. Unless the data were generated using a strand-specific sample prep, it's impossible to distinguish a k-mer from its reverse complement, and they should be treated as the same sequence.</p>\n\n<p>Are there any rolling hashes that will map reverse complements to the same value? If not, how would we develop such an algorithm?</p>\n\n<p><strong>UPDATE</strong>: Ideally the hash function would be able to support k > 32, which would be lossy unless using something larger than a 64-bit integer.</p>\n\n<p><strong>ANOTHER UPDATE</strong>: I don't think it's necessary to <em>store</em> both the running k-mer and its reverse complement in a single value. If storing two k-mer strings and/or two hash values makes this easier, I'm totally cool with that.</p>\n",
        "<p>The standard and the most common sequence format is FASTA for sure. You can compress it with a compressor. For the ~3GB human genome, gzip reduces the size to ~900MB, depending on the option in use.</p>\n\n<p>Another often used format is UCSC's 2-bit format. This format keeps each A/C/G/T with 2 bits. As I remember, it keeps non-A/C/G/T bases and lowercases in two separate lists. These lists basically tell you that bases between offset x and y are all \"N\"/lowercase. The 2-bit format loses IUB codes that GRCh37 has. UCSC's hg19 differs from GRCh37 at a few bases.</p>\n\n<p>BWA also produces its own 2-bit format with indexing. You can generate it separately with:</p>\n\n<pre><code>bwa fa2pac -f hg19.fa\n</code></pre>\n\n<p>Unlike UCSC, BWA keeps all IUB codes but loses letter cases. BWA does not provide utilities to convert its 2-bit representation to FASTA, either.</p>\n\n<p>The 2-bit format typically reduces the file size down to 1/4 of its original size, unless there are too many scattered ambiguous bases. For human genome, you get a file ~784MB in size. You can compress it further with gzip, but that actually doesn't work well. A gzip'd 2-bit file is only ~5-10% smaller.</p>\n\n<p>If you want to achieve an even smaller file size, you can compress the BWT of 2-bit file. This gives you a ~633MB file:</p>\n\n<pre><code>bwa pac2bwtgen hg19.fa.pac tmp.bwt &amp;&amp; gzip tmp.bwt\n</code></pre>\n\n<p>A bit-aware compression algorithm may achieve an even higher compression ratio. However, such BWT-based compression prevents you from extracting subsequences. It is probably of little use in practice.</p>\n",
        "<p>What are the actual differences between different annotation databases? </p>\n\n<p>My lab, for reasons still unknown to me, prefers Ensembl annotations (we're working with transcript/exon expression estimation), while some software ship with RefSeq annotations. Are there significant differences between them today, or are they, for all intents and purposes, interchangeable (e.g., are exon coordinates between RefSeq and Ensembl annotations interchangeable)?</p>\n",
        "<p>The <a href=\"http://cart.embl.de/\" rel=\"noreferrer\">CART</a> tool let's you upload a set of names and map them (optionally in a fuzzy way) to STITCH 4 identifiers, and then use those to map to ATC codes (using the chemicals sources <a href=\"http://stitch4.embl.de/cgi/show_download_page.pl\" rel=\"noreferrer\">download file</a>). It's a bit indirect, and I'm not sure what CART will do with the dosage info you mention.</p>\n",
        "<p><a href=\"https://www.drugbank.ca\" rel=\"noreferrer\">DrugBank</a> seems to have a <a href=\"https://www.drugbank.ca/atc\" rel=\"noreferrer\">tool to map ATC codes to drug names</a> and DrugBank IDs.</p>\n\n<p>A quick look in the XSD schema on the <a href=\"https://www.drugbank.ca/releases/latest\" rel=\"noreferrer\">release page</a> suggests the complete database includes ATC codes for drugs, you could then do a fuzzy match of the BioBank names against all of DrugBank's synonyms, or match on some other data (e.g. canonicalised SMILES) if available.</p>\n\n<p>The downside is that there may not be complete overlap between UK BioBank and DrugBank. Additionally, DrugBank is under licence for commercial use.</p>\n",
        "<p>While the quality of the reference human assembly keeps improving, there are still misassemblies in it. A common problem is recent segmental duplications are occasionally collapsed into one sequence in the reference. Another issue is that the centromeric sequences in the reference are computationally generated, which are probably different from real sequences. Issues like these often complicate data analyses.</p>\n\n<p>You should also beware that each human has a different genome. A large region having one copy in the reference genome may have two copies in a specific sample. While this is not really the problem with the reference, such copy-number changes will have the same effect as reference errors and mess up your pipelines.</p>\n\n<p>There is still room for improvement to the human reference genome. In some regions, the CHM1 and CHM13 PacBio assemblies are better than the current reference genome at the larger scale. Illumina population data can produce better consensus at the single base level. GRC is continuously releasing new patches to the latest assembly.</p>\n",
        "<p>FASTA and FASTQ formats are both file formats that contain sequencing reads while SAM files are these reads aligned to a reference sequence. In other words, FASTA and FASTQ are the &quot;raw data&quot; of sequencing while SAM is the product of aligning the sequencing reads to a refseq.</p>\n<p>A FASTA file contains a read name followed by the sequence. An example of one of these reads for RNASeq might be:</p>\n<pre><code>&gt;Flow cell number: lane number: chip coordinates etc.\nATTGGCTAATTGGCTAATTGGCTAATTGGCTAATTGGCTAATTGGCTAATTGGCTAATTGGCTA\n</code></pre>\n<p>The FASTQ version of this read will have two more lines, one + as a place holder and then a line of quality scores for the base calls. The qualities are given as characters with '!' being the lowest and '~' being the highest, in increasing ASCII value. It would look something like this</p>\n<pre><code>@Flow cell number: lane number: chip coordinates etc.\nATTGGCTAATTGGCTAATTGGCTAATTGGCTAATTGGCTAATTGGCTAATTGGCTAATTGGCTA\n+\n!''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF&gt;&gt;&gt;&gt;&gt;&gt;CCCCCCC65\n</code></pre>\n<p>A SAM file has many fields for each alignment, the header begins with the @ character. The alignment contains 11 mandatory fields and various optional ones. You can find the spec file here: <a href=\"https://samtools.github.io/hts-specs/SAMv1.pdf\" rel=\"nofollow noreferrer\">https://samtools.github.io/hts-specs/SAMv1.pdf</a> .</p>\n<p>Often you'll see BAM files which are just compressed binary versions of SAM files. You can view these alignment files using various tools, such as SAMtools, IGV or USCS Genome browser.</p>\n<p>As to the benefits, FASTA/FASTQ vs. SAM/BAM is comparing apples and oranges. I do a lot of RNASeq work so generally we take the FASTQ files and align them the a refseq using an aligner such as STAR which outputs SAM/BAM files. There's a lot you can do with just these alignment files, looking at expression, but usually I'll use a tool such as RSEM to &quot;count&quot; the reads from various genes to create an expression matrix, samples as columns and genes as rows. Whether you get FASTQ or FASTA files just depends on your sequencing platform. I've never heard of anybody really using the quality scores.</p>\n",
        "<p>Let <code>f</code> and <code>r</code> be two integers. They always keep the k-mer on the forward and reverse strand, respectively. At a new base <code>c</code> in a proper 2-bit encoding, we update the two integers as follows:</p>\n\n<pre><code>f = (f&lt;&lt;2|c) &amp; ((1ULL&lt;&lt;2*k) - 1)\nr = r&gt;&gt;2 | (3ULL-c)&lt;&lt;2*(k-1)\n</code></pre>\n\n<p>With this updating rule, <code>f</code> keeps the forward strand k-mer ending at <code>c</code> and <code>r</code> is <code>f</code>'s reverse complement. The hash of the k-mer can be <code>min(f,r)</code>. If integer operations take constant time, computing the hashes of all k-mers of a sequence of length L takes O(L) time.</p>\n\n<p>The above only works if k-mer fits a word, which means <code>k&lt;=32</code> on x86. For long k-mers, you can overload bit operators in C++. In case of <code>32&lt;k&lt;=64</code>, a simpler solution is to split into lower and higher bits:</p>\n\n<pre><code>c1 = c&amp;1, c2 = c&gt;&gt;1\nf1 = (f1&lt;&lt;1|c1) &amp; ((1ULL&lt;&lt;k) - 1)\nf2 = (f2&lt;&lt;1|c2) &amp; ((1ULL&lt;&lt;k) - 1)\nr1 = r1&gt;&gt;1 | (1ULL-c1)&lt;&lt;(k-1)\nr2 = r2&gt;&gt;1 | (1ULL-c2)&lt;&lt;(k-1)\n</code></pre>\n\n<p>This is twice as slow as the <code>k&lt;=32</code> version. It is possible to implement these lines with SSE2 intrinsics, but that is overkilling.</p>\n\n<p>When you want to hash a long k-mer into fewer bits, there are a few options:</p>\n\n<pre><code>xor:      f^r\nmin:      min(f,r)\nmin+hash: hash(min(f,r))\n</code></pre>\n\n<p>where <code>hash()</code> is a generic randomization hash function, which could be Murmur3, Wang's integer hash function, etc.</p>\n\n<p>The following is a microbenchmark. Here, we squeeze all k-mers into a 32-bit hash table. <code>collision_rate = 1 - #distinct_hash/#distinct_kmer</code>. This is not the best metric, but it somehow measures the randomness, which is better than nothing.</p>\n\n<pre><code>====================================================\n Algorithm    data  max-k  k   %collision  CPU time\n----------------------------------------------------\n xor          chr11  32    31     8.5%       0.9s\n xor+Wang     chr11  32    31     9.6%       1.3s\n min+Wang     chr11  32    31     1.4%       1.3s\n min+Wang     chr11  64    31     1.4%       1.9s\n min+murmur3  chr11  inf   31     1.4%       5.7s\n min+Wang     chr11  64    51     1.5%       2.1s\n min+murmur3  chr11  inf   51     1.5%       6.8s\n min+Wang     chr11  64    63     1.5%       2.1s\n min+murmur3  chr11  inf   63     1.5%       7.5s\n radix sort   chr11  -     -      -        5.6-7.3s\n----------------------------------------------------\n min+Wang     hg38   64    63    26.2%        37s\n min+murmur3  hg38   inf   63    26.2%       192s\n radix sort   hg38   -     -      -         ~138s\n====================================================\n</code></pre>\n\n<p>Observations:</p>\n\n<ul>\n<li><p>Don't use XOR. In fact, XOR hashes all palindromes to <code>0xffff...</code>. This is already worrying enough.</p></li>\n<li><p>Unless you want to work with very long k-mers, don't use generic string hash functions like FNV and Murmur. Murmur is even slower than radix sorting all hashes.</p></li>\n<li><p>For <code>k&lt;=64</code>, min+Wang is the best here. It is fast and simple to compute and has randomness nearly as good as murmur.</p></li>\n</ul>\n",
        "<p>I have a set of BAM files that are aligned using the NCBI GRCh37 human genome reference (with the chromosome names as NC_000001.10) but I want to analyze it using a BED file that has the UCSC hg19 chromosome names (e.g. chr1). I want to use bedtools to pull out all the on-target and off-target reads.</p>\n\n<ol>\n<li>Are NCBI and UCSC directly comparable? Or do I need to re-align the BAM/lift-over the BED to the UCSC reference?</li>\n<li>Should I convert the BED file or the BAM file? Everyone here uses the UCSC chromosome names/positions so I'll need to convert the eventual files to UCSC anyway.</li>\n</ol>\n",
        "<p>If your goal is to minimise storage by just having one hash per kmer and its reverse complement, there is a simple solution for non-rolling hashes. For any sequence S, you compute and store the hash of the smaller of S and its reverse complement. A simple lexicographical comparison for \"smaller\" is enough. In programming terms:</p>\n\n<pre><code>hash=computeHash(min(S,rev(S));\n</code></pre>\n\n<p>If your goal is to minimise computing time via rolling hashes AND store only one kmer value, this will be hard. Hashes are normally designed to minimise collisions and you are asking it not only to collide, but also to collide in very, very specific circumstances.</p>\n\n<p>Question is: is the computation of a hash a bottleneck for an application? Maybe, maybe not.</p>\n\n<p><a href=\"https://softwareengineering.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed/145633#145633\">This</a> post on StackExchange seems to imply that, in 2012, MurmurHash was able to compute de-novo a hash for a UUID (similar to a standard kmer in size and complexity) in ~250ns, i.e., ~4 million hashes per second. That's already quite fast.</p>\n\n<p>My guess is that most applications will use a hash to look up things in memory or disk. And here, even with look-ups in memory, real life data will let you run into CPU cache miss speed penalties very quickly and I expect the impact of this to be higher than the speed of the hash computation itself.</p>\n",
        "<p>What's the most widely accepted tool for doing pseudo-temporal ordering from scRNAseq data? Also is there away to separate differential expression that occurs based on \"cell identity\" or maybe more accurately cell type fate from that which arises from cells being in different stages differentiation.</p>\n\n<p>To be more concrete, lets say there's a population of cells, some of which were born at time 1, time 2, and time 3. The progression along the temporal trajectory can be described via a set of genes that are fluctuating as the cell matures. So you might have the same cell type which was born at time 1 be transcriptionally distinct from a younger one born at time 3.  On the other hand, within this population there are subpopulations which will have different cell fates and are transcriptionally distinct. Is there away to reliably separate the temporal axis from the \"cell fate axes\". If not is this something people are working on or is flawed logic to think this kind of thing is possible?</p>\n",
        "<p>The <a href=\"https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&amp;PAGE_TYPE=BlastDocs&amp;DOC_TYPE=BlastHelp\" rel=\"nofollow noreferrer\">FASTA format</a> has a single-line definition (defline), followed by one or more lines of DNA, RNA or amino acid sequences. The definition line is specified by the greater than (<code>&gt;</code>) character.</p>\n",
        "To be used for questions specific tothe  sequence file format `.fasta`.\r\n\r\nPlease minimise usage if the question is more generally about sequence formats.",
        "<p>You're the second person I have ever seen using NCBI \"chromosome names\" (they're more like supercontig IDs). Normally I would point you to <a href=\"https://github.com/dpryan79/ChromosomeMappings\" rel=\"noreferrer\">a resource providing mappings between chromosome names</a>, but since no one has added NCBI names (yet, maybe I'll add them now) you're currently out of luck there.</p>\n\n<p>Anyway, the quickest way to do what you want is to <code>samtools view -H foo.bam &gt; header</code> to get the BAM header and then change each NCBI \"chromosome name\" to its corresponding UCSC chromosome name. DO NOT REORDER THE LINES! You can then use <code>samtools reheader</code> and be done.</p>\n\n<p>Why, you might ask, would this work? The answer is that chromosome/contig names in BAM files aren't stored in each alignment. Rather, the names are stored in a list in the header and each alignment just contains the integer index into that list (read group IDs are similar, for what it's worth). This also leads to the warning above against reordering entries, since that's a VERY convenient way to start swapping alignments between chromosomes.</p>\n\n<p>As an aside, you'd be well served switching to Gencode or Ensembl chromosome names, they're rather more coherent than the <code>something_random</code> mess that's present in hg19 from UCSC.</p>\n\n<p><strong>Update</strong>: Because I'm nice, <a href=\"https://github.com/dpryan79/ChromosomeMappings/blob/master/GRCh37_NCBI2UCSC.txt\" rel=\"noreferrer\">here</a> is the conversion between NCBI and UCSC. Note that if you have any alignments to patches that there is simply no UCSC equivalent. One of the many reasons not to use UCSC (avoid their annotations too).</p>\n",
        "<p>To quote the Introduction to <code>BWA</code> on <a href=\"http://bio-bwa.sourceforge.net/\" rel=\"noreferrer\">sourceforge</a>:</p>\n\n<blockquote>\n  <p>BWA is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome. It consists of three algorithms: BWA-backtrack, BWA-SW and BWA-MEM. The first algorithm is designed for Illumina sequence reads up to 100bp, while the rest two for longer sequences ranged from 70bp to 1Mbp. BWA-MEM and BWA-SW share similar features such as long-read support and split alignment, but BWA-MEM, which is the latest, is generally recommended for high-quality queries as it is faster and more accurate. BWA-MEM also has better performance than BWA-backtrack for 70-100bp Illumina reads.</p>\n</blockquote>\n\n<p>In short, for anything where you have read lengths over 70bp BWA-MEM is faster, and more accurate.</p>\n",
        "<p>I have run Oxford Nanopore Technologies' MinION sequencing on the same DNA sample using three flowcells, each aligned against the same reference genome (E.coli K12 MG1655) using both BWA MEM and GraphMap and stored as BAM files.</p>\n\n<p>How can I quantitatively and efficiently analyse the quality of alignment (percentage identity, insertion rate, deletion rate) of each of these files?</p>\n",
        "<h2>Ensembl vs Gencode</h2>\n\n<p><a href=\"https://www.gencodegenes.org/faq.html\" rel=\"noreferrer\">https://www.gencodegenes.org/faq.html</a></p>\n\n<blockquote>\n  <p>The GENCODE annotation is made by merging the Havana manual gene annotation and the Ensembl automated gene annotation. [...] In practical terms, the GENCODE annotation is identical to the Ensembl annotation.</p>\n</blockquote>\n\n<p>Further, for the GTF file differences:</p>\n\n<blockquote>\n  <p>The only exception is that the genes which are common to the human chromosome X and Y PAR regions can be found twice in the GENCODE GTF, while they are shown only for chromosome X in the Ensembl file.</p>\n</blockquote>\n\n<h2>Gencode(Ensembl) vs RefSeq</h2>\n\n<p>Gencode is in almost all cases <a href=\"https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-16-S8-S2\" rel=\"noreferrer\">more comprehensive</a>. For example, this is NCBI RefSeq vs Ensembl (v24, release 83) for BRCA gene:\n<a href=\"https://i.stack.imgur.com/MO5Gb.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/MO5Gb.png\" alt=\"enter image description here\"></a></p>\n\n<p>RefSeq and Gencode are not interchangeable in most cases, though RefSeq annotations will often be a subset of the Gencode ones.</p>\n",
        "<p>Qualimap will do this for you. </p>\n\n<ol>\n<li>Go to <a href=\"http://qualimap.bioinfo.cipf.es\" rel=\"nofollow noreferrer\">qualimap.bioinfo.cipf.es</a></li>\n<li>Run qualimap (default params are fine) on each BAM file</li>\n<li>Open up the HTML output, and you can read off the %identity (they measure the opposite, i.e. mismatch rate, but 100% - mismatch rate is %identity of course), indel rate, etc.</li>\n</ol>\n\n<p>One thing to watch out for (you don't mention it in your question, but just in case) is that you cannot directly compare Q scores - these are a bit of a mess and calculated very differently in each piece of software. </p>\n\n<p>Unsolicited suggestion: you might also try <a href=\"https://github.com/philres/ngmlr\" rel=\"nofollow noreferrer\">NGM-LR</a> for mapping MinION data. We've found it beats the others for our data (though we map to a distant reference).</p>\n",
        "<p>I think the question is a bit ambiguous so please excuse this answer that's a bit redundant from the rest of the ones provided.</p>\n\n<p>As others have mentioned, if you want to store a full genome, <a href=\"https://en.wikipedia.org/wiki/FASTA_format\" rel=\"noreferrer\"><code>FASTA</code></a> and <a href=\"https://genome.ucsc.edu/FAQ/FAQformat.html#format7\" rel=\"noreferrer\"><code>2bit</code></a> formats are appropriate.  For some context, <a href=\"http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/\" rel=\"noreferrer\"><code>hg19</code></a> is about 900Mb compressed for the <code>FASTA</code> file and about 780Mb compressed for the <code>2bit</code> file .  <code>hg19</code> is a reference and is haploid so doesn't represent a \"full\" human genome that would normally have two alleles for the autosome (non-sex chromosomes).</p>\n\n<p>A common format for representing variant information is Variant Call Format (<a href=\"https://vcftools.github.io/specs.html\" rel=\"noreferrer\"><code>VCF</code></a>). The <code>VCF</code> format represent differences from a reference (<code>hg19</code>, say) that can be used to recover the original full sequence by using the reference and the differences encoded in the <code>VCF</code> file.  I've seen <code>VCF</code> files in the range of 100Mb, but a reference file is still needed to recover the full genome sequence which is the range of 800Mb+, as mentioned above.</p>\n\n<p>If you're considering just one \"whole genome\" in isolation, then the answer is pretty clear: <code>2bit</code> format is probably approaching the entropy limit of the human genome and you probably won't be able to do much better.\nThe reason why your question is a bit ambiguous is that as soon as you start encoding more than one genome, a population of genomes, say, then you can start exploiting the redundancy of the genome as shared by the population.</p>\n\n<p>For example, say you want to store two \"whole genomes\".  You could download the <code>hg19</code> reference and download two <code>VCF</code> files which would give around 1Gb worth of data (around 800Mb for the <code>2bit</code> file and around 200Mb for both of the <code>VCF</code> files).  Now you've been able to represent a \"whole genome\" in 500Mb instead of the 800Mb.  You can see a similar argument for downloading 3 <code>VCF</code> files and more.</p>\n\n<p>The minimum amount of information needed to represent a population of genomes is, as far as I know, unknown, but I would guess in the 2.5Mb-5Mb range.  For example, see <a href=\"https://academic.oup.com/bioinformatics/article/25/2/274/218156/Human-genomes-as-email-attachments\" rel=\"noreferrer\">\"Human genomes as email attachments\" by Christley, Lu, Li and Xie</a> which claims a 4Mb encoding of a genome.  </p>\n\n<p>Things get tricky because you have to ask what you're claiming as a \"whole genome\".  <code>VCF</code> files are notoriously bad because older versions of the specification only store high quality differences from reference, throwing away high quality called sections.  If you want to store low quality information, the encoding is now going to depend on the sequencing technology in weird ways.</p>\n\n<p>Insertions, deletions, mobile insertion elements, copy number variants, other structural variants, etc. all complicate this matter further.  <a href=\"http://biorxiv.org/content/early/2017/01/18/101378\" rel=\"noreferrer\">Genome Graphs</a> are trying to tackle at least some of these problems but the focus is on variant calling rather than efficient individual whole genome representation, though perhaps can be adapted in the future.</p>\n",
        "<p>While I have no experience with this <em>specific</em> question you have, according to Feinstein &amp; Brylinski (<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4468813/\" rel=\"nofollow noreferrer\">2015</a>), a \"fully automated procedure\", i.e. a Perl script, can be used to optimize the box size itself, and it can be found <a href=\"http://brylinski.cct.lsu.edu/content/docking-box-size\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
        "<p>I have a single ~10GB FASTA file generated from an Oxford Nanopore Technologies' MinION run, with &gt;1M reads of mean length ~8Kb. How can I quickly and efficiently calculate the distribution of read lengths?</p>\n<p>A naive approach would be to read the FASTA file in Biopython, check the length of each sequence, store the lengths in a numpy array and plot the results using matplotlib, but this seems like reinventing the wheel.</p>\n<p>Many solutions that work for short reads are inadequate for long reads. If I'm hey output a single (text) line per 1/10 bases, which would lead to a text output of upwards of 10,000 lines (and potentially more than 10x that) for a long read fasta.</p>\n",
        "<p>I have a computer engineering background, not biology.</p>\n\n<p>I started working on a bioinformatics project recently, which involves <em>de-novo</em> assembly. I came to know the terms <code>Transcriptome</code> and <code>Genome</code>, but I cannot identify the difference between these two.</p>\n\n<p>I know a transcriptome is the set of all messenger RNA molecules in a cell, but am not sure how this is different from a genome.</p>\n",
        "<p>In brief, the  \u201cgenome\u201d  is the collection of all  DNA  present  in  the  nucleus  and  the  mitochondria of a  somatic  cell. The initial product of genome expression is the \u201ctranscriptome\u201d, a collection of RNA molecules derived from those genes.</p>\n",
        "<p>There are several potential approaches. For example:</p>\n\n<ul>\n<li><a href=\"http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc295\" rel=\"noreferrer\">histogram of sequence lengths</a> in the Biopython tutorial</li>\n<li><a href=\"https://github.com/maasha/biopieces/wiki/plot_distribution\" rel=\"noreferrer\">plot_distribution</a> from the Ruby-based biopieces framework</li>\n<li>various solutions to get sequence length <a href=\"https://gif.biotech.iastate.edu/calculate-sequence-lengths-fasta-file\" rel=\"noreferrer\">including bioawk</a> and <a href=\"https://www.biostars.org/p/118954/#119066\" rel=\"noreferrer\">EMBOSS infoseq</a></li>\n</ul>\n\n<p>As to which of these are \"quick and efficient\" using a 10 GB file...it's hard to say in advance. You may have to try and benchmark a few of them.</p>\n",
        "<p>They are two very different things. Your genome is a large section of about 3 billion DNA nucleotide bases. It has no concept of exon and introns.</p>\n\n<p>Transcriptome is a study of <a href=\"https://en.wikipedia.org/wiki/Transcription_(biology)\" rel=\"noreferrer\">transcriptions</a>. You have introns and exons. We can now talk about alternative splicing and gene expression.</p>\n\n<p>You can think your genome is like a cooking recipe. While it's good to have a good recipe, you can't do much if you don't use it for cooking. </p>\n",
        "<p>I want to focus on transcriptome analysis. We know it's possible to analyze RNA-Seq experiment based on alignment or k-mers.</p>\n\n<p>Possible alignment workflow:</p>\n\n<ul>\n<li>Align sequence reads with <a href=\"https://ccb.jhu.edu/software/tophat/index.shtml\" rel=\"noreferrer\">TopHat2</a></li>\n<li>Quantify the gene expression with <a href=\"http://cole-trapnell-lab.github.io/cufflinks/install/\" rel=\"noreferrer\">Cufflinks</a></li>\n</ul>\n\n<p>Possible reference-free workflow:</p>\n\n<ul>\n<li>Quantify sequence reads with <a href=\"https://pachterlab.github.io/kallisto/\" rel=\"noreferrer\">Kallisto</a> reference-free index</li>\n</ul>\n\n<p>Both strategy generate gene expression table.</p>\n\n<p><strong>Q:</strong> What are pros and cons for each of the approach? Can you give guideline?</p>\n",
        "<p><a href=\"https://www.thermofisher.com/order/catalog/product/4456740\" rel=\"noreferrer\">ERCC spike-in</a> is a set of synthetic controls developed for RNA-Seq. I'm interested in using it to normalize my RNA-Seq samples. In particular, I'd like to use the spike-ins to remove technical bias and any variation that should not be part of my analysis.</p>\n\n<p>The site doesn't give any details on how I can do that.</p>\n\n<p><strong>Q:</strong> What are the possible normalization strategies? Can you briefly describe them?</p>\n",
        "<p>You may consider using <a href=\"http://bioconductor.org/packages/release/bioc/html/RUVSeq.html\" rel=\"nofollow noreferrer\">RUVSeq</a>. Here is an excerpt from the <a href=\"http://www.nature.com/nbt/journal/v32/n9/full/nbt.2931.html\" rel=\"nofollow noreferrer\">2013 Nature Biotechnology publication</a>:</p>\n\n<blockquote>\n  <p>We evaluate the performance of the External RNA Control Consortium (ERCC) spike-in controls and investigate the possibility of using them directly for normalization. We show that the spike-ins are not reliable enough to be used in standard global-scaling or regression-based normalization procedures. We propose a normalization strategy, called remove unwanted variation (RUV), that adjusts for nuisance technical effects by performing factor analysis on suitable sets of control genes (e.g., ERCC spike-ins) or samples (e.g., replicate libraries).</p>\n</blockquote>\n\n<p>RUVSeq essentially fits a generalized linear model (GLM) to the expression data, where your expression matrix $Y$ is a $m$ by $n$ matrix, where $m$ is the number of samples and $n$ the number of genes. The model boils down to</p>\n\n<p>$Y = X*\\beta + Z*\\gamma + W*\\alpha + \\epsilon$</p>\n\n<p>where $X$ describes the conditions of interest (e.g., treatment vs. control), $Z$ describes observed covariates (e.g., gender) and $W$ describes unobserved covariates (e.g., batch, temperature, lab). $\\beta$, $\\gamma$ and $\\alpha$ are parameter matrices which record the contribution of $X$, $Z$ and $W$, and $\\epsilon$ is random noise. For subset of carefully selected genes (e.g., ERCC spike-ins, housekeeping genes, or technical replicates) we can assume that $X$ and $Z$ are zero, and find $W$ - the \"unwanted variation\" in your sample. </p>\n",
        "<p>I wouldn't say <a href=\"https://pachterlab.github.io/kallisto/\" rel=\"noreferrer\">Kallisto</a> (or <a href=\"http://salmon.readthedocs.io/en/latest/\" rel=\"noreferrer\">Salmon</a>) are reference-free. They use a transcriptome as reference anda concept called <em>pseudo-alignment</em> which greatly speed up the process of assigning your reads to a transcript.</p>\n\n<p>That said, both approaches of (i) mapping against a reference genome (what you called <em>alignment workflow</em> ) and (ii) mapping against a reference transcriptome will serve different purposes</p>\n\n<p>Transcriptome mapping using pseudoalignent is becoming the method of choice for gene/transcript quantification and differential expression analysis. The drawback is that you only focus on known transcripts</p>\n\n<p>Two typical workflows are:</p>\n\n<ul>\n<li>Kallisto followed by <a href=\"http://pachterlab.github.io/sleuth/\" rel=\"noreferrer\">sleuth</a></li>\n<li>Salmon, followed by tximport and DESeq2/EdgeR</li>\n</ul>\n\n<p>Genome mapping is useful for, per example discovery of new isoforms. You shouldn't use TopHat anymore as it has been discontinued by the author.</p>\n\n<p>A typical workflow would be:</p>\n\n<ul>\n<li>Hisat2 (alignment)</li>\n<li>StringTie (transcript assembly and abundance estimation)</li>\n<li>Ballgown (differential expression)</li>\n</ul>\n",
        "<p>It is not exactly what you asked, but you can generate a histogram of read length distribution of your nanopore data directly from the HDF5 files using <a href=\"https://poretools.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">poretools</a></p>\n",
        "<p>A popular framework to analyze differences between groups, either experiments or diseases, in transcriptomics is using linear models (<a href=\"http://bioconductor.org/packages/limma\" rel=\"noreferrer\">limma</a> is a popular choice). </p>\n\n<p>For instance we have a disease D with three stages as defined by clinicians, A, B and C. 10 samples each stage and the healthy H to compare with is RNA-sequenced. A typical linear model would be to observe the three stages<code>~A+B+C</code> independently. The data of each stage is not from the same person. (but for the question assume it isn't)</p>\n\n<p>My understanding is that such a model would not take into account that stage C appears only on 30% of patients in stage B. And that a healthy patient upon external factors can jump to stage B. </p>\n\n<p>If we want to find the role of a gene in the disease we should include somehow this information in the model. Which makes me think about mixing linear models and hidden Markov chains.</p>\n\n<p>How can such a disease be described in terms of linear models with such data and information?</p>\n",
        "<p>Using Biopython and matplotlib would seem like the way to go, indeed.\nIt really just boils down to three lines of code to get that graph:</p>\n\n<pre><code>import Bio, pandas\nlengths = map(len, Bio.SeqIO.parse('/path/to/the/seqs.fasta', 'fasta'))\npandas.Series(lengths).hist(color='gray', bins=1000)\n</code></pre>\n\n<p>Of course you might want to make a longer script that's callable from the command line, with a couple options. You are welcome to use mine:</p>\n\n<pre><code>#!/usr/bin/env python2\n\n\"\"\"\nA custom made script to plot the distribution of lengths\nin a fasta file.\n\nWritten by Lucas Sinclair.\nKopimi.\n\nYou can use this script from the shell like this:\n$ ./fastq_length_hist --input seqs.fasta --out seqs.pdf\n\"\"\"\n\n###############################################################################\n# Modules #\nimport argparse, sys, time, getpass, locale\nfrom argparse import RawTextHelpFormatter\nfrom Bio import SeqIO\nimport pandas\n\n# Matplotlib #\nimport matplotlib\nmatplotlib.use('Agg', warn=False)\nfrom matplotlib import pyplot\n\n################################################################################\ndesc = \"fasta_length_hist v1.0\"\nparser = argparse.ArgumentParser(description=desc, formatter_class=RawTextHelpFormatter)\n\n# All the required arguments #\nparser.add_argument(\"--input\", help=\"The fasta file to process\", type=str)\nparser.add_argument(\"--out\", type=str)\n\n# All the optional arguments #\nparser.add_argument(\"--x_log\", default=True, type=bool)\nparser.add_argument(\"--y_log\", default=True, type=bool)\n\n# Parse it #\nargs        = parser.parse_args()\ninput_path  = args.input\noutput_path = args.out\nx_log       = bool(args.x_log)\ny_log       = bool(args.y_log)\n\n################################################################################\n# Read #\nlengths = map(len, SeqIO.parse(input_path, 'fasta'))\n\n# Report #\nsys.stderr.write(\"Read all lengths (%i sequences)\\n\" % len(lengths))\nsys.stderr.write(\"Longest sequence: %i bp\\n\" % max(lengths))\nsys.stderr.write(\"Shortest sequence: %i bp\\n\" % min(lengths))\nsys.stderr.write(\"Making graph...\\n\")\n\n# Data #\nvalues = pandas.Series(lengths)\n\n# Plot #\nfig   = pyplot.figure()\naxes  = values.hist(color='gray', bins=1000)\nfig   = pyplot.gcf()\ntitle = 'Distribution of sequence lengths'\naxes.set_title(title)\naxes.set_xlabel('Number of nucleotides in sequence')\naxes.set_ylabel('Number of sequences with this length')\naxes.xaxis.grid(False)\n\n# Log #\nif x_log: axes.set_yscale('symlog')\nif y_log: axes.set_xscale('symlog')\n\n# Adjust #\nwidth=18.0; height=10.0; bottom=0.1; top=0.93; left=0.07; right=0.98\nfig.set_figwidth(width)\nfig.set_figheight(height)\nfig.subplots_adjust(hspace=0.0, bottom=bottom, top=top, left=left, right=right)\n\n# Data and source #\nfig.text(0.99, 0.98, time.asctime(), horizontalalignment='right')\nfig.text(0.01, 0.98, 'user: ' + getpass.getuser(), horizontalalignment='left')\n\n# Nice digit grouping #\nsep = ('x','y')\nif 'x' in sep:\n    locale.setlocale(locale.LC_ALL, '')\n    seperate = lambda x,pos: locale.format(\"%d\", x, grouping=True)\n    axes.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(seperate))\nif 'y' in sep:\n    locale.setlocale(locale.LC_ALL, '')\n    seperate = lambda x,pos: locale.format(\"%d\", x, grouping=True)\n    axes.yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(seperate))\n\n# Save it #\nfig.savefig(output_path, format='pdf')\n</code></pre>\n\n<p>EDIT - an example output:</p>\n\n<p><a href=\"https://i.stack.imgur.com/5kmaX.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5kmaX.png\" alt=\"Sequence length distribution\"></a></p>\n",
        "<p>First of all, I would emphasize that \"alignment-free\" quantification tools like Salmon and Kallisto are <em>not</em> reference-free. The basic difference between them and more traditional aligners is that they do not report a specific position (either in a genome or transcriptome) to which a read maps. However, their overall purpose is still to quantify the expression levels (or differences) of a known set of transcripts; hence, they require a reference (which could be arbitrarily defined).</p>\n\n<p>The most important criterion for deciding which approach to use (and this is true of almost everything in genomics) is exactly what question you would like to answer. If you are primarily interested in quantifying and comparing expression of mature mRNA from known transcripts, then a transcriptome-based alignment may be fastest and best. However, you may miss potentially interesting features outside of those known transcripts, such as new isoforms, non-coding RNAs, or information about pre-mRNA levels, which can often be gleaned from intronic reads (see the <a href=\"https://www.nature.com/nbt/journal/v33/n7/full/nbt.3269.html\" rel=\"nofollow noreferrer\">EISA</a> method).</p>\n\n<p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4729156/\" rel=\"nofollow noreferrer\">This paper</a> also has some good considerations about which tools may work best depending on the question you want to answer.</p>\n\n<p>Finally, another fast and flexible aligner (which can be used with or without a reference transcriptome) is <a href=\"https://github.com/alexdobin/STAR\" rel=\"nofollow noreferrer\">STAR</a>.</p>\n",
        "",
        ""
    ],
    "beer": [
        "<p>I was offered a beer the other day that was reportedly made with citra hops. What are citra hops? Why should I care that my beer is made with them?</p>\n",
        "<p>As far as we know, when did humans first brew beer, and where? Around when would you have been able to get your hands on something resembling a modern lager?</p>\n",
        "<p>How is low/no alcohol beer made? I'm assuming that the beer is made normally and the alcohol is then removed, is it any more than just boiling it off? I've noticed that no/low alcohol beers' taste improved hugely a few years ago, is this due to a new technique?</p>\n",
        "<p>Citra is a registered trademark since 2007. Citra Brand hops have fairly high alpha acids and total oil contents with a low percentage of cohumulone content and  imparts interesting citrus and tropical fruit characters to beer.</p>\n\n<p>For more information, you can read the <a href=\"http://en.wikipedia.org/wiki/List_of_hop_varieties#Citra_brand_HBC_394_cv\">Wikipedia article</a> on the Citra brand.</p>\n",
        "<p>In general, what's the best way to work out the temperature at which to serve a particular beer? Room temperature? Cold? Supercold? <em>Warm?</em></p>\n",
        "<p>Currently I am storing my bottles in the crates at a (about) 20 degree angle (bottles are upwards!).</p>\n\n<p>Does the way of storing the bottles affect something (and how)?</p>\n",
        "<p>Assuming we're comparing equivalent amounts of alcohol, do certain beers get you inebriated more quickly or slowly? Does the amount of fizz make a difference?</p>\n",
        "<p>Apart from coming out of different taps, some ales seem very similar to lagers (although there are clearly a much greater variety of ales). Is there a difference in the way they are made?</p>\n",
        "<p>It's pretty cold at the moment. Mulled wine being more of a Christmas drink, mulled beer is getting popular. What beers, and what spices should I use to make it?</p>\n",
        "<p>I usually drink <em>strong</em> Belgian Ales, particularly Triples, Quads and Trappists, so I'm no stranger to strong beer.  But I've noticed that I get far, far worse hangovers when drinking IPAs.  </p>\n\n<p>Is there anything about IPAs that would make this possible?  The lower quality places like ask.com or Yahoo answers usually say no, that only ABV produces hangovers, though one source did seem to imply that IPAs have special ingredients that make this a possibility. </p>\n\n<p>So I want to ask the experts here: do IPAs have ingredients that other strong beers lack, that could exacerbate hangovers? </p>\n",
        "<p>Given craft beers, which are typically brewed without many preservatives, what is the average duration a beer must sit inside a barrel before it is ready for serving?</p>\n\n<p>If different types of beer require different brewing times, can you provide a list?</p>\n",
        "<p>There are a couple of ways to do that.</p>\n\n<p>The two main \"approaches\" are to extract the alcohol afterwards or just don't allow the generation of it.</p>\n\n<p>The extracting part can be achieved by filtering and reverse osmosis. Alcohol and water are getting sucked out and the \"beer mass\" gets re-watered. These steps may affect the taste quit a bit. A few brewers (especially in Germany) have developed a \"top secret\" technique to brew a alcohol free beer which tastes the same as \"normal\" beer - but most of these are \"top secret\".</p>\n\n<p>Latest science experiements revealed a new way of brewing alcohol free beer, by just stopping the fermentation process. This can be done by lowering the temperature of the liquid containers.</p>\n\n<p>Beers brewed with this technique tend to taste more sweet.</p>\n\n<p>Both method have their up and downs so a couple brewers combined both: Less fermentation than usual and extracting the extra bits of alcohol.</p>\n",
        "<p>Beer varies widely, and one of the most noticeable differences when drinking is the carbonation level.  What factors in the composition, brewing process, storage, etc affect the final level of carbonation? </p>\n",
        "<p>Bottled beer is significantly different than the same label beer available on tap.</p>\n\n<p>How does bottled beer differ from draught beer? What is done to the bottled beer in order to prolong its shelf life in the bottle?</p>\n\n<p>And finally, why does draught beer taste so much better than bottled beer?</p>\n",
        "<p>When going out for some beers, after a while, I seem to pee more than the amount of beer I drink. Is that true, and why is that?</p>\n\n<p><img src=\"https://i.stack.imgur.com/rL13S.jpg\" alt=\"enter image description here\"></p>\n",
        "<p>Ales and lagers are brewed with different types of yeast.  Ale yeast ferments at the top of the brewing vat at a comfortable room temperature while lager yeast ferments at the bottom of the vat at a lower temperature.  The \"low and slow\" lager fermentation brings out more complex flavors.</p>\n",
        "<p>Ale yeast strains are best used at temperatures ranging from 10 to 25\u00b0C, though some strains will not actively ferment below 12\u00b0C (33). Ale yeasts are generally regarded as top-fermenting yeasts since they rise to the surface during fermentation, creating a very thick, rich yeast head. That is why the term \"top-fermenting\" is associated with ale yeasts. Fermentation by ale yeasts at these relatively warmer temperatures produces a beer high in esters, which many regard as a distinctive character of ale beers. </p>\n\n<p>Top-fermenting yeasts are used for brewing ales, porters, stouts, Altbier, K\u00f6lsch, and wheat beers. *</p>\n\n<p>Lager yeast strains are best used at temperatures ranging from 7 to 15\u00b0C. At these temperatures, lager yeasts grow less rapidly than ale yeasts, and with less surface foam they tend to settle out to the bottom of the fermenter as fermentation nears completion. This is why they are often referred to as \"bottom\" yeasts. The final flavour of the beer will depend a great deal on the strain of lager yeast and the temperatures at which it was fermented. </p>\n\n<p>Some of the lager styles made from bottom-fermenting yeasts are Pilsners, Dortmunders, M\u00e4rzen, Bocks, and American malt liquors.* </p>\n\n<p>(All information from <a href=\"https://www.beeradvocate.com/\">BeerAdvocate</a>.)</p>\n",
        "<p>It depends on the beer really.  A good rule of thumb is darker beer should be served at a warmer temperature than lighter beer.</p>\n\n<p>For instance if you refrigerate all of your beers and then pull them out of the fridge and drink them instantly you will miss A LOT of the flavor complexity of pretty much every stout and porter you put to your lips.</p>\n\n<p>But, if you let the dark stuff warm up for just 15 minutes before you drink it (let it sit at room temp) a bunch of new flavors will appear that you never would have noticed otherwise.</p>\n\n<p>This doesn't work so well, in my experience, for lighter beers like pilsner, lager, or hefe-weisen.  They really are meant to be drank cold and letting them get warm changes their flavor profile for the worse.</p>\n\n<p>Obviously there will always be personal preferences but, at a minimum I encourage you to try letting your darker beers warm up just a bit and see what a positive difference it makes.</p>\n\n<p>Here is a temperature guide from this article: <a href=\"http://www.ratebeer.com/Story.asp?StoryID=479\" rel=\"noreferrer\">Serving Temperature Guide</a>. It categorizes different beers based on temps to serve at.  These are basic rules of thumb and again you'll want to experiment and discover what temps you like your beers at the best.</p>\n",
        "<p>It all depends on the beer really. Lagers are typically brewed longer than ales. Of the few brews I've made so far, I usually let them ferment for 2 weeks in the fermenter, then I bottle them and wait another 2 weeks.</p>\n",
        "<p>I frequently hear stories about people drinking their favorite pilsener, and not liking the other brand because \"they'll get a hangover when drinking that brand\".</p>\n\n<p>Is there a truth in this?</p>\n",
        "<p>I understand the basic distinction for wine glasses: red wine glasses are shaped to help keep some of the aroma inside the glass, whereas whites don't. But shapes for beer glasses, such as pilsner vs a standard pint glass, just seem to be an aesthetic difference. Yet I've had people insist that glasses make a big difference for things like Belgian beer. </p>\n\n<p>Is there a sound reason to use the \"right\" glass for each kind of beer? </p>\n",
        "<p>I suspect this really boils down to each persons' chemistry.  IPA's don't have any real negative impact on me in terms of hangovers but Budweiser (as a prime example) has a much faster onset of hangover for me and I suffer far worse from it.</p>\n\n<p>The \"Ice Beers\" that became popular in the early 90's really caused me to have a lot of problems but, again, IPA's of all stripes typically don't bother me at all.</p>\n",
        "<p>The primary difference is the yeast used to ferment the beer -- ales use yeasts strains which work at a warmer temperature (10-25 deg C) than lager yeasts strains (7-15 deg C).  You may hear the terms \"top-fermenting\" for ale yeasts and \"bottom-fermenting\" for lagers, but I think that's more-or-less happen-stance -- the yeasts themselves are not inclined toward a particular altitude.</p>\n",
        "<p>My local growler shop regularly has a variety of stouts on tap, of which I usually pick Imperial. </p>\n\n<p>What, specifically, distinguishes an Imperial stout from other kinds of stouts (say a regular stout, an oatmeal stout etc)?</p>\n",
        "<p>Yes.  Taste is really smell, and different glasses can capture aromas differently.  Furthermore, different aromas may be more or less present dependent upon temperature, and a glass may be crafted to be held a particular way (gathering more or less heat from your hand).  The same is true for wine glasses.</p>\n\n<p>That said, how much of a difference it makes <em>to you</em> is what's important.  Going back to the wine comparison, I can sometimes tell the difference between different glasses, but not consistently.  So it's not the <em>most</em> important thing.</p>\n\n<p>Now that <em>that's</em> said, there has been some informal, perhaps less than perfectly scientific studies, including a <a href=\"http://drinks.seriouseats.com/2012/06/beer-glasses-best-glass-for-craft-beer-taste-test.html\">blind test</a>.  Beer advocate provides some more <a href=\"http://beeradvocate.com/beer/101/glassware/\">detailed information</a>.  Some of my local bars carry stemware for specific European beers, and I know of one stateside brewery, Black Shirt Brewing in Denver, which really wants you to <a href=\"http://www.fermentedlychallenged.com/2012/06/black-shirt-brewing-to-feature-offero.html\">stick your nose up in it</a> (to good effect, in my experience).</p>\n",
        "<p>There are two main ways to carbonate beer. </p>\n\n<p>Force carbonation - This is where CO2 is forced into the fermented beer. Because of the pressure (and the temperature at which it is done) the CO2 will dissolve into the beer solution. The fizz that happens when you open a beer is the CO2 coming out of solution. (Technically you can re-carbonate flat beer!)</p>\n\n<p>Natural carbonation - All beer has SOME yeast present. Home-brewers that bottle will actually pour a little bit of sugar into the racked beer before bottling. The yeast that is present will re-activate and eat the sugar. One of the bi-products is CO2. Because the beer is bottled and the CO2 has nowhere to go, it will dissolve into solution. This is why you will often see little yeast cakes in the bottom of home-brewer's bottles.</p>\n\n<p>There are some beers that used forced-nitrogen to nitrogenate (if that is the appropriate word) their beers. </p>\n\n<p>TL;DR - Temperature, methods of carbonating, storing beer can all affect carbonation. </p>\n",
        "<p>I know what makes an IPA an IPA, but what are the unique characteristics of it's common variants? To be specific, the ones I'm interested in are Double IPA and Black IPA, but general differences between any other styles would be welcome too. </p>\n",
        "<p>I'm trying to understand what I can assume about an \"Imperial Stout\" relative to a \"Stout,\" etc.</p>\n\n<p>I know anecdotally that they are \"heavier,\" but online sources seem to lack agreement on a specific meaning, with some suggesting that they're hoppier, others saying they're higher alcohol content, and some using vague terms like \"full-bodied\".</p>\n\n<p>Does \"imperial\" have a real, agreed-upon meaning, or is it just a marketing/description modifier that everyone uses differently?</p>\n",
        "<p>Beer in a growler typically lasts for 24 hours or less, depending on how full the growler is, how many times it's opened over that period of time, and how efficient the seal is on the lid. Are there ways of prolonging the life in a growler or at least seal it properly?</p>\n",
        "<p>Alcohol is a diuretic.  According to <a href=\"http://www.drinkaware.co.uk/check-the-facts/health-effects-of-alcohol/effects-on-the-body/why-does-alcohol-make-you-pee-more\">this article</a>, 1 gram of alcohol will increase urine excretion by 10ml.  Combine that with <a href=\"http://www.cdc.gov/alcohol/faqs.htm#standDrink\">this CDC article</a> stating that a standard 12 ounce (354ml) beer has 14 grams of alcohol, your can expect to pee 494ml, or 16.75 ounces per 12 ounce bottle.</p>\n\n<p>The graphic would be more accurate with you drinking three beers but peeing four.</p>\n",
        "<p>Porters and stouts seem very similar and sometimes stores and restaurants group them together as if they're two different names for the same thing.</p>\n\n<p>Is there a difference and what is it?</p>\n",
        "<p>The term \"imperial\" generally means \"strong\", as in having a higher ABV.  You may also find \"Imperial IPAs\" (aka IIPAs, or sometimes Double or Triple IPAs), and again, they are boosting the alcohol content.  The actual ingredients (hops, or oatmeal, as per your example) do not come into play, except to balance the flavors against the malt.</p>\n",
        "<p>Some beers (for example, Guinness) are marked as 'not suitable for vegans'. What is in the beer such that this is the case?</p>\n",
        "<p>Is there a widely accepted glass shape/type for Saison's (and if so, what is it)? Is a different glass used for French Saison's vs. Belgian Saison's vs. other common Saison styles?</p>\n",
        "<p>Sometimes I buy beer more quickly than I can drink it -- a sad state of affairs, I know, but it happens.  I know that some beers are best drunk within a few weeks and others can be fine for months, but I don't know which are which.  What are the rules of thumb for this?  How can I determine how long a bottle of beer will keep before starting to lose its taste?  (Assume appropriate storage.)</p>\n",
        "<p>As the well known rhyme reminds us, drinking beer after wine is a bad idea. Having made the mistake during my student years more than once and regretting it, why is it that consuming these two beverages in the wrong order causes such effects?</p>\n",
        "<p>The first Imperial Stout was made by Thrale's Brewery to export to the Russian royalty, it had high alcoholic content so that it could survive the trip gracefully <a href=\"http://www.wellsandyoungs.co.uk/home/news/courage-imperial-russian-stout\" rel=\"noreferrer\">[1]</a>. Since then Imperial has been used as a prefix to signify beers which are of higher alcohol volume than their normal variants, and luckily they're no longer just for Russian royalty.</p>\n",
        "<p>Stouts are stout, Pale Ales use pale malt, but where did the name porter come from?</p>\n",
        "<p>There are a few theories out there, and their veracity, like that of most historical \"facts\", is hotly debated.</p>\n\n<p>One theory begins in 1722 when Ralph Harwood, a London brewer, created a beer called <em>Entire</em>.  For some time, working folk had been drinking a blend of beer, ale, and strong beer, which pubs would mix to balance out their stocks and maintain acceptable flavor.  </p>\n\n<p><em>Entire</em> was a pre-mixed version, brewed by Hardwood then sold and delivered to pubs.  Prior to this point, each pub had mixed their own.  In addition to economies of scale, Harwood's method allowed for aging of the finished product.  Historians theorize that the name <em>porter</em> came about because of the porters who worked at the markets and delivered the final product to the pubs.  A variation of this theory suggests that <em>porter</em> simply refers to the working class occupations of those who drank the concoction.</p>\n\n<p>Another theory suggests that <em>porter</em> comes from the Netherlands, where a beer called <em>poorter</em> was being made as early as the 1300s.  The Dutch were prolific traders, and cultural transfer could easily have occurred.  The term <em>poorter</em> originally concerned inhabitants of walled cities and may also have been related to social station.</p>\n",
        "<p>Beer Connoisseur Online answers this pretty thoroughly in <a href=\"https://beerconnoisseur.com/articles/difference-between-porter-and-stout\">an article</a>.  </p>\n\n<p>The TLDR: is that \"...originally a stout was a strong version of a porter.  Today, the difference is whatever you want it to be.\"</p>\n\n<p>For an interesting history on the term Stout and the style of beer, you can check out this <a href=\"http://www.realbeer.com/library/authors/smith-g/stout.php\">history of stout article</a> provided by Eric Deloak.  Similarly you can read a <a href=\"http://www.realbeer.com/library/authors/smith-g/porter.php\">history of porter article</a> written by the same author: Gregg Smith</p>\n",
        "<p>Some beer use animal by-products in their production.  Guinness is popular example: <a href=\"http://en.wikipedia.org/wiki/Isinglass\">isinglass</a>, a swim bladder, is as a filter or fining agent.</p>\n",
        "<p>There are two main ingredients in beer that might cause them to be unsuitable for vegans. The first one might be fairly obvious. Honey is sometimes used as a sweetener, especially in meade, but certainly in other beers.</p>\n\n<p>However, the main cause is a fining agent called <a href=\"http://en.wikipedia.org/wiki/Isinglass\">Isinglass</a> that is made from ground swim bladders of fish.</p>\n",
        "<p>Absolutely, it depends on the ABV like any other alcoholic beverage. You can drink Natty-lights all night like college kids or you can get your hands on one of <a href=\"http://www.huffingtonpost.com/2013/10/24/worlds-strongest-beer-snake-venom_n_4157580.html#slide=2580657\" rel=\"nofollow\">these bad boys, at 67.5% abv.</a> I highly doubt carbonation has anything to do with it. </p>\n\n<p>Personally, I prefer to drink beer for the taste, not to get drunk. So I'll experiment among many different craft brews.</p>\n\n<p>---- edit ----</p>\n\n<p>Started answering before I saw your edit. I'll keep this up for education's sake.</p>\n",
        "<p>I'm not sure about when the first beer was <em>made</em>, but the oldest existing brewery is <a href=\"http://www.totalbeveragesolution.com/weihenstephan/\">Weihenstephan</a>, which dates back to 1040 AD, a good 26 years before the battle of Hastings. </p>\n\n<p>They have not only lager, but a Hefeweizen, Dunkel, and a few other brews.</p>\n",
        "<p>I recently encountered a beer that was utterly rank and had an awful aroma. I tasted a small sip, but had to toss the rest. Investigating the label on this beer, I discovered it had an expiry date of Dec. 2012, making it just over one year old. </p>\n\n<p>This beer's alcohol content was 5.6% ABV, and it clearly did not have a lengthy self life.</p>\n\n<p>Contrastingly, a local brewer annually brews an ice bock with an alcohol content of 9.5% ABV, and they state that because of this high alcohol content, it's suitable for aging (and it ages well, to boot).</p>\n\n<p><strong>What is the minimum alcohol content/ABV percentage required in order to consider a beer safe/suitable for aging? If pasteurization plays a role, please advise.</strong></p>\n",
        "<p>There are some rules of thumb.  First, if it's a hop-oriented beer (pales, IPAs), drink sooner than later, as the hop aromas and flavor will fade over time.  Second, the higher the alcohol by volume (ABV, think imperial stouts), the better chance it has of lasting longer.</p>\n\n<p>That said, it may be best to ask the brewer what the recommended shelf life is for any <em>specific</em> beer.</p>\n",
        "<h3>EDIT to add sources (original answer below)</h3>\n<p>Mythbusters address this in episode 127 - <a href=\"http://mythresults.com/dirty-vs-clean-car\" rel=\"nofollow noreferrer\">http://mythresults.com/dirty-vs-clean-car</a> - the <em>rate</em> of consumption is what matters, not the <em>order</em></p>\n<blockquote>\n<h3>A hangover caused by beer is less severe than one caused by a mixture of beer and liquor.</h3>\n<h2>BUSTED</h2>\n<p>To perform this test, Tory and Grant would have to eat the same food, drink their alcohol at the same time, and sleep for the same length of time in the warehouse for consistent results. Kari (who could not take part because of her pregnancy) then devised a battery of tests to measure dehydration, memory, light/sound/motion sensitivity, and coordination. Without having drunk alcohol, Tory and Grant performed well on their control test. They then performed the beer test, with Tory drinking 14 cans of beer and Grant drinking six. They both performed significantly worse than the control tests, signifying they were badly hung over. They then repeated the test with a mixture of beer and liquor, making sure to drink an equivalent amount of alcohol as in the first test. The next morning, Tory and Grant improved significantly and felt much better than in the previous test. Thus, the Build Team declared the myth busted.</p>\n</blockquote>\n<p>NYTimes also addressed this back in 2006 - <a href=\"http://www.nytimes.com/2006/02/07/health/the-claim-mixing-types-of-alcohol-makes-you-sick.html\" rel=\"nofollow noreferrer\">http://www.nytimes.com/2006/02/07/health/the-claim-mixing-types-of-alcohol-makes-you-sick.html</a></p>\n<blockquote>\n<p>&quot;The pattern, more often, is that people will have beer and then move on to liquor at the end of the night, and so they think it's the liquor that made them sick,&quot; he continued. &quot;But simply mixing the two really has nothing to do with it.&quot;</p>\n</blockquote>\n<hr />\n<p>In general, the ABV of wine is higher than that of beer, so if you consume a higher ABV after a lower ABV, you will feel its effects faster, but if you're still drinking at the same rate, you won't notice you've had any effect as readily as if you drank at the slower rate more generally associated with the higher ABV beverage.</p>\n",
        "<p>In my fraternity days, there was a constant fear of beer (typically kegged but also bottled) getting \"skunked\" as a result of warming up and cooling down too many times, possibly even once.</p>\n\n<p>Do non-extreme temperature changes such as moving a beer back and forth from a counter to a refrigerator cause perceptible changes to beer?  If not, what about more extreme changes, such as sitting in the bed of a truck or a trunk?  I'm aware that light has a degrading affect on it's own, so let's assume this beer is in a keg or a light-proof box.</p>\n",
        "<p>As you might expect, it's all got to do with the ingredients. I'm a vegetarian myself, but not a vegan. So I do eat honey and dairy. With that said, some beers would not be considered vegan if they use those ingredients (milk stouts for instance use lactose).</p>\n\n<p>However, an example of a non-vegetarian beer would be the oyster stout, which uses oysters in the brewing process. </p>\n",
        "<p>The process of becoming drunk involves becoming dehydrated. So the higher the ABV, and less water you're taking on, the faster you'll feel the effects. </p>\n\n<p>This is why shots get you drunk very quickly: there is little to no extra water in the mix. Other ingredients can add to this affect, and as I've personally noticed, some beers can produce very different \"drunk experiences\" than others - just like being drunk off wine, beer, shots, or mixed drinks can produce different results.</p>\n\n<p>So, absolutely if you drank half a beer with twice the ABV while your friend drank 1 beer with half the ABV, you'd probably feel drunk faster than him. Assuming you're drinking at the same pace. Less water.</p>\n",
        "<p>Various microbreweries make chocolate stout that does indeed, to varying degrees, taste of chocolate. Does it really contain chocolate, and how is chocolate used in the brewing process?</p>\n"
    ]
}